{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import sys,os  \n",
    "caffe_root = '/data/ssd-caffe/yolov3-caffe/'\n",
    "sys.path.insert(0, caffe_root + 'python')  \n",
    "import caffe  \n",
    "\n",
    "#train_proto = 'yolov3-tiny-ncs-without-last-maxpool.prototxt'\n",
    "#train_model = 'snapshot/mobilenet_iter_7000.caffemodel'  #should be your snapshot caffemodel\n",
    "train_proto = 'yolov3.prototxt'\n",
    "deploy_proto = 'yolov3_merged_bn.prototxt'\n",
    "'''if(len(sys.argv) < 2):\n",
    "    print(\"please input caffemodel file from commandLine\")\n",
    "    exit(1)\n",
    "train_model = sys.argv[1]'''\n",
    "\n",
    "#deploy_proto = 'yolov3-tiny-ncs-without-last-maxpool-merg-batchnorm.prototxt'  \n",
    "#save_model = 'iter_7000_MobileNetSSD_deploy.caffemodel'\n",
    "#save_model = train_model.split('/')[-1] + \"MobileNetSSD_deploy.caffemodel\"\n",
    "save_model = \"generated_merge_yolov3.caffemodel\"\n",
    "#global buf #----why can not work ?\n",
    "\n",
    "def merge_bn(net, nob):\n",
    "    '''\n",
    "    merge the batchnorm, scale layer weights to the conv layer, to  improve the performance\n",
    "    var = var + scaleFacotr\n",
    "    rstd = 1. / sqrt(var + eps)\n",
    "    w = w * rstd * scale\n",
    "    b = (b - mean) * rstd * scale + shift\n",
    "    '''\n",
    "    buf = [0, 2, 0, 960000, 0]\n",
    "    for key in net.params.iterkeys():\n",
    "        print(\"key:\" + str(key))\n",
    "        if type(net.params[key]) is caffe._caffe.BlobVec:\n",
    "            print(\"is caffe._caffe.BlobVec\")\n",
    "            if key.endswith(\"-bn\") or key.endswith(\"-scale\"):\n",
    "                continue\n",
    "            else:\n",
    "                conv = net.params[key]\n",
    "                print(\"merge layer {0}\".format(conv))\n",
    "                if not net.params.has_key(key[:-5] + \"-bn\"):\n",
    "                    print(\"not need bn, copy w and b\")\n",
    "                    for i, w in enumerate(conv):\n",
    "                        #print(\"i={0}\".format(i))\n",
    "                        nob.params[key][i].data[...] = w.data\n",
    "                        #print(w.data.shape)\n",
    "                    temp_array = (conv[1].data).reshape(-1)                       \n",
    "                    buf = buf + temp_array.tolist()\n",
    "                    print(len(buf))\n",
    "                    temp_array = (conv[0].data).reshape(-1)                       \n",
    "                    buf = buf + temp_array.tolist()\n",
    "                    print(len(buf))\n",
    "                else:\n",
    "                    \n",
    "                    print(\"need bn, really start bn and scale\")\n",
    "                    bn = net.params[key[:-5] + \"-bn\"]\n",
    "                    scale = net.params[key[:-5] + \"-scale\"]\n",
    "                    wt = conv[0].data\n",
    "                    channels = wt.shape[0]\n",
    "                    bias = np.zeros(wt.shape[0])\n",
    "                    if len(conv) > 1:\n",
    "                        bias = conv[1].data\n",
    "                    mean = bn[0].data\n",
    "                    var = bn[1].data\n",
    "                    scalef = bn[2].data\n",
    "                    print('scalef = {0}'.format(scalef))\n",
    "\n",
    "                    scales = scale[0].data\n",
    "                    shift = scale[1].data\n",
    "\n",
    "                    if scalef != 0:\n",
    "                        scalef = 1. / scalef\n",
    "                    mean = mean * scalef\n",
    "                    var = var * scalef\n",
    "                    rstd = 1. / np.sqrt(var + 1e-5)\n",
    "                    rstd1 = rstd.reshape((channels,1,1,1))\n",
    "                    scales1 = scales.reshape((channels,1,1,1))\n",
    "                    wt = wt * rstd1 * scales1\n",
    "                    bias = (bias - mean) * rstd * scales + shift                   \n",
    "                    nob.params[key][0].data[...] = wt                   \n",
    "                    nob.params[key][1].data[...] = bias\n",
    "                    \n",
    "                    print(bias.shape)\n",
    "                    temp_array = bias.reshape(-1)\n",
    "                    buf = buf + temp_array.tolist()\n",
    "                    print(len(buf))\n",
    "                    \n",
    "                    print(wt.shape)\n",
    "                    temp_array = wt.reshape(-1)\n",
    "                    buf = buf + temp_array.tolist()\n",
    "                    print(len(buf))\n",
    "    weights_merged_bn = np.array(buf, dtype=np.float32)\n",
    "    print(weights_merged_bn)\n",
    "    fp = open('aaa_yolov3.weights', \"wb\")\n",
    "    weights_merged_bn.tofile(fp)\n",
    "    #np.save('npsaved_file', weights_merged_bn)\n",
    "\n",
    "#net = caffe.Net(train_proto, train_model, caffe.TRAIN)\n",
    "caffe.set_mode_cpu()\n",
    "#net = caffe.Net(train_proto, 'Jenerated_nolastpooling.caffemodel', caffe.TEST)\n",
    "net = caffe.Net(train_proto, 'yolov3.caffemodel', caffe.TEST)\n",
    "net_deploy = caffe.Net(deploy_proto, caffe.TEST)  \n",
    "\n",
    "merge_bn(net, net_deploy)\n",
    "#net_deploy.save(save_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(np.ndarray.tofile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
