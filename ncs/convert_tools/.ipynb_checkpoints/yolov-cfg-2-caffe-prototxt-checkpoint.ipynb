{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/ssd-caffe/py2_caffe/python/', '/data/ssd-caffe/py2_caffe/python/', '/data/ssd-caffe/py2_caffe/python/', '/data/ssd-caffe/new-yolov3-caffe/python', '/data/ssd-caffe/py2_caffe/python/', '/data/ssd-caffe/py2_caffe/python/', '/data/ssd-caffe/py2_caffe/python/', '/data/ssd-caffe/py2_caffe/python/', '', '/data/github_repos/yolov3-tiny-fit-ncs/ncs/convert_tools', '/data/ssd-caffe/caffe/python', '/data/ssd-caffe/new-yolov3-caffe/python', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/home/yyp/.local/lib/python2.7/site-packages', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages/gtk-2.0', '/home/yyp/.local/lib/python2.7/site-packages/IPython/extensions', '/home/yyp/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.insert(0,'/data/ssd-caffe/py2_caffe/python/')\n",
    "import caffe  \n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from ConfigParser import ConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniqDict(OrderedDict):\n",
    "    _unique = 0\n",
    "    def __setitem__(self, key, val):\n",
    "        if isinstance(val, OrderedDict):\n",
    "            self._unique += 1\n",
    "            key += \"_\"+str(self._unique)\n",
    "        OrderedDict.__setitem__(self, key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cfg(cfgfile):\n",
    "    parser = ConfigParser(dict_type=UniqDict)\n",
    "    parser.read(cfgfile)\n",
    "    blocks = parser.sections()\n",
    "    return blocks, parser\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfg2prototxt(cfgfile):\n",
    "    blocks, parser = parse_cfg(cfgfile)\n",
    "    print(blocks)\n",
    "    layers = []  \n",
    "    props = OrderedDict()  \n",
    "    bottom = 'data'  \n",
    "    layer_id = 1  \n",
    "    topnames = dict()  \n",
    "    for block in blocks:\n",
    "        items = dict(parser.items(block))\n",
    "        items['type'] = block.split('_')[0]\n",
    "        print(items)\n",
    "        if items['type'] == 'net':  \n",
    "            props['name'] = 'Darkent2Caffe'  \n",
    "            props['input'] = 'data'  \n",
    "            props['input_dim'] = ['1']  \n",
    "            props['input_dim'].append(items['channels'])  \n",
    "            props['input_dim'].append(items['height'])  \n",
    "            props['input_dim'].append(items['width'])  \n",
    "            continue  \n",
    "        elif (items['type'] == 'convolutional' or items['type'] == 'deconvolutional'):  \n",
    "            conv_layer = OrderedDict()  \n",
    "            conv_layer['bottom'] = bottom  \n",
    "            if items.has_key('name'):  \n",
    "                conv_layer['top'] = items['name']  \n",
    "                conv_layer['name'] = items['name']  \n",
    "            else:\n",
    "                if(items['type'] == 'convolutional'):\n",
    "                    conv_layer['top'] = 'layer%d-conv' % layer_id  \n",
    "                    conv_layer['name'] = 'layer%d-conv' % layer_id\n",
    "                elif(items['type'] == 'deconvolutional'):\n",
    "                    conv_layer['top'] = 'layer%d-upsample' % layer_id  \n",
    "                    conv_layer['name'] = 'layer%d-upsample' % layer_id\n",
    "                    \n",
    "            if(items['type'] == 'deconvolutional'):\n",
    "                conv_layer['type'] = 'Deconvolution'\n",
    "            elif(items['type'] == 'convolutional'):\n",
    "                conv_layer['type'] = 'Convolution' \n",
    "            convolution_param = OrderedDict()  \n",
    "            convolution_param['num_output'] = items['filters']  \n",
    "            convolution_param['kernel_size'] = items['size']  \n",
    "            if items['pad'] == '1':  \n",
    "                convolution_param['pad'] = str(int(convolution_param['kernel_size'])/2)  \n",
    "            convolution_param['stride'] = items['stride']\n",
    "            if items.has_key('batch_normalize'):\n",
    "                if items['batch_normalize'] == '1':  \n",
    "                    convolution_param['bias_term'] = 'false' \n",
    "            else:  \n",
    "                convolution_param['bias_term'] = 'true'  \n",
    "            conv_layer['convolution_param'] = convolution_param  \n",
    "            layers.append(conv_layer)  \n",
    "            bottom = conv_layer['top']  \n",
    "            if items.has_key('batch_normalize'):\n",
    "                if items['batch_normalize'] == '1': \n",
    "                    bn_layer = OrderedDict()  \n",
    "                    bn_layer['bottom'] = bottom  \n",
    "                    bn_layer['top'] = bottom  \n",
    "                    if items.has_key('name'):  \n",
    "                        bn_layer['name'] = '%s-bn' % items['name']  \n",
    "                    else:  \n",
    "                        bn_layer['name'] = 'layer%d-bn' % layer_id  \n",
    "                    bn_layer['type'] = 'BatchNorm'  \n",
    "                    batch_norm_param = OrderedDict()  \n",
    "                    batch_norm_param['use_global_stats'] = 'true'  \n",
    "                    bn_layer['batch_norm_param'] = batch_norm_param  \n",
    "                    layers.append(bn_layer)  \n",
    "\n",
    "                    scale_layer = OrderedDict()  \n",
    "                    scale_layer['bottom'] = bottom  \n",
    "                    scale_layer['top'] = bottom  \n",
    "                    if items.has_key('name'):  \n",
    "                        scale_layer['name'] = '%s-scale' % items['name']  \n",
    "                    else:  \n",
    "                        scale_layer['name'] = 'layer%d-scale' % layer_id  \n",
    "                    scale_layer['type'] = 'Scale'  \n",
    "                    scale_param = OrderedDict()  \n",
    "                    scale_param['bias_term'] = 'true'  \n",
    "                    scale_layer['scale_param'] = scale_param  \n",
    "                    layers.append(scale_layer)  \n",
    "\n",
    "            if items['activation'] != 'linear':  \n",
    "                relu_layer = OrderedDict()  \n",
    "                relu_layer['bottom'] = bottom  \n",
    "                relu_layer['top'] = bottom  \n",
    "                if items.has_key('name'):  \n",
    "                    relu_layer['name'] = '%s-act' % items['name']  \n",
    "                else:  \n",
    "                    relu_layer['name'] = 'layer%d-act' % layer_id  \n",
    "                relu_layer['type'] = 'ReLU'  \n",
    "                if items['activation'] == 'leaky':  \n",
    "                    relu_param = OrderedDict()  \n",
    "                    relu_param['negative_slope'] = '0.1'  \n",
    "                    relu_layer['relu_param'] = relu_param  \n",
    "                layers.append(relu_layer)  \n",
    "            topnames[layer_id] = bottom  \n",
    "            layer_id = layer_id+1  \n",
    "        elif items['type'] == 'maxpool':  \n",
    "            max_layer = OrderedDict()  \n",
    "            max_layer['bottom'] = bottom  \n",
    "            if items.has_key('name'):  \n",
    "                max_layer['top'] = items['name']  \n",
    "                max_layer['name'] = items['name']  \n",
    "            else:  \n",
    "                max_layer['top'] = 'layer%d-maxpool' % layer_id  \n",
    "                max_layer['name'] = 'layer%d-maxpool' % layer_id  \n",
    "            max_layer['type'] = 'Pooling'  \n",
    "            pooling_param = OrderedDict()  \n",
    "            pooling_param['kernel_size'] = items['size']  \n",
    "            pooling_param['stride'] = items['stride']  \n",
    "            pooling_param['pool'] = 'MAX'  \n",
    "            if items.has_key('pad') and int(items['pad']) == 1:  \n",
    "                pooling_param['pad'] = str((int(items['size'])-1)/2)  \n",
    "            max_layer['pooling_param'] = pooling_param  \n",
    "            layers.append(max_layer)  \n",
    "            bottom = max_layer['top']  \n",
    "            topnames[layer_id] = bottom  \n",
    "            layer_id = layer_id+1  \n",
    "        elif items['type'] == 'avgpool':  \n",
    "            avg_layer = OrderedDict()  \n",
    "            avg_layer['bottom'] = bottom  \n",
    "            if block.has_key('name'):  \n",
    "                avg_layer['top'] = items['name']  \n",
    "                avg_layer['name'] = items['name']  \n",
    "            else:  \n",
    "                avg_layer['top'] = 'layer%d-avgpool' % layer_id  \n",
    "                avg_layer['name'] = 'layer%d-avgpool' % layer_id  \n",
    "            avg_layer['type'] = 'Pooling'  \n",
    "            pooling_param = OrderedDict()  \n",
    "            pooling_param['kernel_size'] = 7  \n",
    "            pooling_param['stride'] = 1  \n",
    "            pooling_param['pool'] = 'AVE'  \n",
    "            avg_layer['pooling_param'] = pooling_param  \n",
    "            layers.append(avg_layer)  \n",
    "            bottom = avg_layer['top']  \n",
    "            topnames[layer_id] = bottom  \n",
    "            layer_id = layer_id+1  \n",
    "        elif items['type'] == 'yolo': \n",
    "            layer_id = layer_id + 1\n",
    "            continue\n",
    "            region_layer = OrderedDict()  \n",
    "            region_layer['bottom'] = bottom  \n",
    "            if items.has_key('name'):  \n",
    "                region_layer['top'] = items['name']  \n",
    "                region_layer['name'] = items['name']  \n",
    "            else:  \n",
    "                region_layer['top'] = 'layer%d-yolo' % layer_id  \n",
    "                region_layer['name'] = 'layer%d-yolo' % layer_id  \n",
    "            region_layer['type'] = 'Yolo'  \n",
    "            region_param = OrderedDict()  \n",
    "            region_param['anchors'] = items['anchors'].strip()  \n",
    "            region_param['classes'] = items['classes']  \n",
    "            region_param['num'] = items['num']  \n",
    "            region_layer['yolo_param'] = region_param  \n",
    "            layers.append(region_layer)  \n",
    "            bottom = region_layer['top']  \n",
    "            topnames[layer_id] = bottom  \n",
    "            layer_id = layer_id + 1\n",
    "\n",
    "        elif items['type'] == 'route':\n",
    "            route_layer = OrderedDict()  \n",
    "            layer_name = str(items['layers']).split(',')  \n",
    "            print(layer_name[0])  \n",
    "            bottom_layer_size = len(str(items['layers']).split(','))  \n",
    "        #print(bottom_layer_size)  \n",
    "            if(1 == bottom_layer_size):  \n",
    "                prev_layer_id = layer_id + int(items['layers'])  \n",
    "                bottom = topnames[prev_layer_id]  \n",
    "                #topnames[layer_id] = bottom  \n",
    "            route_layer['bottom'] = bottom  \n",
    "            if(2 == bottom_layer_size):  \n",
    "                prev_layer_id1 = layer_id + int(layer_name[0])  \n",
    "                #print(prev_layer_id1)  \n",
    "                prev_layer_id2 = int(layer_name[1]) + 1  \n",
    "                print(topnames)  \n",
    "                bottom1 = topnames[prev_layer_id1]  \n",
    "                bottom2 = topnames[prev_layer_id2]  \n",
    "                route_layer['bottom'] = [bottom1, bottom2]  \n",
    "            if items.has_key('name'):  \n",
    "                route_layer['top'] = items['name']  \n",
    "                route_layer['name'] = items['name']  \n",
    "            else:  \n",
    "                route_layer['top'] = 'layer%d-route' % layer_id  \n",
    "                route_layer['name'] = 'layer%d-route' % layer_id  \n",
    "            route_layer['type'] = 'Concat'\n",
    "            print(route_layer)  \n",
    "            layers.append(route_layer)  \n",
    "            bottom = route_layer['top']  \n",
    "            print(layer_id)  \n",
    "            topnames[layer_id] = bottom  \n",
    "            layer_id = layer_id + 1  \n",
    "\n",
    "        elif items['type'] == 'upsample':\n",
    "            upsample_layer = OrderedDict()  \n",
    "            print(items['stride'])  \n",
    "            upsample_layer['bottom'] = bottom  \n",
    "            if items.has_key('name'):  \n",
    "                upsample_layer['top'] = items['name']  \n",
    "                upsample_layer['name'] = items['name']  \n",
    "            else:  \n",
    "                upsample_layer['top'] = 'layer%d-upsample' % layer_id  \n",
    "                upsample_layer['name'] = 'layer%d-upsample' % layer_id  \n",
    "            upsample_layer['type'] = 'Upsample'  \n",
    "            upsample_param = OrderedDict()  \n",
    "            upsample_param['scale'] = items['stride']  \n",
    "            upsample_layer['upsample_param'] = upsample_param  \n",
    "            print(upsample_layer)  \n",
    "            layers.append(upsample_layer)  \n",
    "            bottom = upsample_layer['top']  \n",
    "            print('upsample:',layer_id)  \n",
    "            topnames[layer_id] = bottom  \n",
    "            layer_id = layer_id + 1  \n",
    "\n",
    "        elif items['type'] == 'shortcut':  \n",
    "            prev_layer_id1 = layer_id + int(items['from'])  \n",
    "            prev_layer_id2 = layer_id - 1  \n",
    "            bottom1 = topnames[prev_layer_id1]  \n",
    "            bottom2= topnames[prev_layer_id2]  \n",
    "            shortcut_layer = OrderedDict()  \n",
    "            shortcut_layer['bottom'] = [bottom1, bottom2]  \n",
    "            if items.has_key('name'):  \n",
    "                shortcut_layer['top'] = items['name']  \n",
    "                shortcut_layer['name'] = items['name']  \n",
    "            else:  \n",
    "                shortcut_layer['top'] = 'layer%d-shortcut' % layer_id  \n",
    "                shortcut_layer['name'] = 'layer%d-shortcut' % layer_id  \n",
    "            shortcut_layer['type'] = 'Eltwise'\n",
    "            eltwise_param = OrderedDict()  \n",
    "            eltwise_param['operation'] = 'SUM'  \n",
    "            shortcut_layer['eltwise_param'] = eltwise_param  \n",
    "            layers.append(shortcut_layer)  \n",
    "            bottom = shortcut_layer['top']  \n",
    "\n",
    "            if items['activation'] != 'linear':  \n",
    "                relu_layer = OrderedDict()  \n",
    "                relu_layer['bottom'] = bottom  \n",
    "                relu_layer['top'] = bottom  \n",
    "                if block.has_key('name'):  \n",
    "                    relu_layer['name'] = '%s-act' % items['name']  \n",
    "                else:  \n",
    "                    relu_layer['name'] = 'layer%d-act' % layer_id  \n",
    "                relu_layer['type'] = 'ReLU'  \n",
    "                if items['activation'] == 'leaky':  \n",
    "                    relu_param = OrderedDict()  \n",
    "                    relu_param['negative_slope'] = '0.1'  \n",
    "                    relu_layer['relu_param'] = relu_param  \n",
    "                layers.append(relu_layer)  \n",
    "            topnames[layer_id] = bottom  \n",
    "            layer_id = layer_id + 1             \n",
    "\n",
    "        elif items['type'] == 'connected':  \n",
    "            fc_layer = OrderedDict()  \n",
    "            fc_layer['bottom'] = bottom  \n",
    "            if items.has_key('name'):  \n",
    "                fc_layer['top'] = items['name']  \n",
    "                fc_layer['name'] = items['name']  \n",
    "            else:  \n",
    "                fc_layer['top'] = 'layer%d-fc' % layer_id  \n",
    "                fc_layer['name'] = 'layer%d-fc' % layer_id  \n",
    "            fc_layer['type'] = 'InnerProduct'  \n",
    "            fc_param = OrderedDict()  \n",
    "            fc_param['num_output'] = int(items['output'])  \n",
    "            fc_layer['inner_product_param'] = fc_param  \n",
    "            layers.append(fc_layer)  \n",
    "            bottom = fc_layer['top']  \n",
    "\n",
    "            if items['activation'] != 'linear':  \n",
    "                relu_layer = OrderedDict()  \n",
    "                relu_layer['bottom'] = bottom  \n",
    "                relu_layer['top'] = bottom  \n",
    "                if items.has_key('name'):  \n",
    "                    relu_layer['name'] = '%s-act' % items['name']  \n",
    "                else:  \n",
    "                    relu_layer['name'] = 'layer%d-act' % layer_id  \n",
    "                relu_layer['type'] = 'ReLU'  \n",
    "                if items['activation'] == 'leaky':  \n",
    "                    relu_param = OrderedDict()  \n",
    "                    relu_param['negative_slope'] = '0.1'  \n",
    "                    relu_layer['relu_param'] = relu_param  \n",
    "                layers.append(relu_layer)  \n",
    "            topnames[layer_id] = bottom  \n",
    "            layer_id = layer_id+1  \n",
    "        else:  \n",
    "            print('unknow layer type %s ' % items['type'])  \n",
    "            topnames[layer_id] = bottom  \n",
    "            layer_id = layer_id + 1  \n",
    "\n",
    "    net_info = OrderedDict()  \n",
    "    net_info['props'] = props  \n",
    "    net_info['layers'] = layers  \n",
    "    return net_info \n",
    "def save_prototxt(net_info, protofile, yolo=False):\n",
    "    fp = open(protofile, 'w')\n",
    "    # whether add double quote\n",
    "    def format_value(value):\n",
    "        #str = u'%s' % value\n",
    "        #if str.isnumeric():\n",
    "        if is_number(value):\n",
    "            return value\n",
    "        elif value == 'true' or value == 'false' or value == 'MAX' or value == 'SUM' or value == 'AVE':\n",
    "            return value\n",
    "        else:\n",
    "            return '\\\"%s\\\"' % value\n",
    "\n",
    "    def print_block(block_info, prefix, indent):\n",
    "        blanks = ''.join([' ']*indent)\n",
    "        print >>fp, '%s%s {' % (blanks, prefix)\n",
    "        for key,value in block_info.items():\n",
    "            if type(value) == OrderedDict:\n",
    "                print_block(value, key, indent+4)\n",
    "            elif type(value) == list:\n",
    "                for v in value:\n",
    "                    print >> fp, '%s    %s: %s' % (blanks, key, format_value(v))\n",
    "            else:\n",
    "                print >> fp, '%s    %s: %s' % (blanks, key, format_value(value))\n",
    "        print >> fp, '%s}' % blanks\n",
    "        \n",
    "    props = net_info['props']\n",
    "    layers = net_info['layers']\n",
    "    print >> fp, 'name: \\\"%s\\\"' % props['name']\n",
    "    print >> fp, 'input: \\\"%s\\\"' % props['input']\n",
    "    print >> fp, 'input_shape{'\n",
    "    print >> fp, '  dim: %s' % props['input_dim'][0]\n",
    "    print >> fp, '  dim: %s' % props['input_dim'][1]\n",
    "    print >> fp, '  dim: %s' % props['input_dim'][2]\n",
    "    print >> fp, '  dim: %s' % props['input_dim'][3]\n",
    "    print >> fp, '}'\n",
    "    #print >> fp, ''\n",
    "    for layer in layers:\n",
    "        if layer['type'] != 'yolo' or yolo == True:\n",
    "            print_block(layer, 'layer', 0)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgfile = '/data/github_repos/darknet/ncs/yolov3-tiny-ncs-without-last-maxpool.cfg'\n",
    "#cfgfile = '/data/darknet/cfg/yolov3.cfg'\n",
    "#cfg2prototxt(cfgfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['net_1', 'convolutional_2', 'maxpool_3', 'convolutional_4', 'maxpool_5', 'convolutional_6', 'maxpool_7', 'convolutional_8', 'maxpool_9', 'convolutional_10', 'maxpool_11', 'convolutional_12', 'convolutional_13', 'convolutional_14', 'convolutional_15', 'convolutional_16', 'yolo_17', 'route_18', 'convolutional_19', 'deconvolutional_20', 'route_21', 'convolutional_22', 'convolutional_23', 'yolo_24']\n",
      "{'hue': '.1', 'saturation': '1.5', 'angle': '0', 'decay': '0.0005', 'learning_rate': '0.001', 'scales': '.1,.1', 'batch': '1', 'height': '416', 'channels': '3', 'width': '416', 'subdivisions': '1', 'burn_in': '1000', 'policy': 'steps', 'max_batches': '500200', 'steps': '400000,450000', 'type': 'net', 'momentum': '0.9', 'exposure': '1.5'}\n",
      "{'activation': 'leaky', 'stride': '1', 'pad': '1', 'filters': '16', 'batch_normalize': '1', 'type': 'convolutional', 'size': '3'}\n",
      "{'stride': '2', 'type': 'maxpool', 'size': '2'}\n",
      "{'activation': 'leaky', 'stride': '1', 'pad': '1', 'filters': '32', 'batch_normalize': '1', 'type': 'convolutional', 'size': '3'}\n",
      "{'stride': '2', 'type': 'maxpool', 'size': '2'}\n",
      "{'activation': 'leaky', 'stride': '1', 'pad': '1', 'filters': '64', 'batch_normalize': '1', 'type': 'convolutional', 'size': '3'}\n",
      "{'stride': '2', 'type': 'maxpool', 'size': '2'}\n",
      "{'activation': 'leaky', 'stride': '1', 'pad': '1', 'filters': '128', 'batch_normalize': '1', 'type': 'convolutional', 'size': '3'}\n",
      "{'stride': '2', 'type': 'maxpool', 'size': '2'}\n",
      "{'activation': 'leaky', 'stride': '1', 'pad': '1', 'filters': '256', 'batch_normalize': '1', 'type': 'convolutional', 'size': '3'}\n",
      "{'stride': '2', 'type': 'maxpool', 'size': '2'}\n",
      "{'activation': 'leaky', 'stride': '1', 'pad': '1', 'filters': '512', 'batch_normalize': '1', 'type': 'convolutional', 'size': '3'}\n",
      "{'activation': 'leaky', 'stride': '1', 'pad': '1', 'filters': '1024', 'batch_normalize': '1', 'type': 'convolutional', 'size': '3'}\n",
      "{'activation': 'leaky', 'stride': '1', 'pad': '1', 'filters': '256', 'batch_normalize': '1', 'type': 'convolutional', 'size': '1'}\n",
      "{'activation': 'leaky', 'stride': '1', 'pad': '1', 'filters': '512', 'batch_normalize': '1', 'type': 'convolutional', 'size': '3'}\n",
      "{'activation': 'linear', 'stride': '1', 'pad': '1', 'filters': '33', 'type': 'convolutional', 'size': '1'}\n",
      "{'jitter': '.3', 'anchors': '10,14,  23,27,  37,58,  81,82,  135,169,  344,319', 'random': '1', 'mask': '3,4,5', 'num': '6', 'classes': '6', 'ignore_thresh': '.7', 'truth_thresh': '1', 'type': 'yolo'}\n",
      "{'layers': '-4', 'type': 'route'}\n",
      "-4\n",
      "OrderedDict([('bottom', 'layer13-conv'), ('top', 'layer17-route'), ('name', 'layer17-route'), ('type', 'Concat')])\n",
      "17\n",
      "{'activation': 'leaky', 'stride': '1', 'pad': '1', 'filters': '128', 'batch_normalize': '1', 'type': 'convolutional', 'size': '1'}\n",
      "{'activation': 'leaky', 'stride': '2', 'pad': '0', 'filters': '128', 'type': 'deconvolutional', 'size': '2'}\n",
      "{'layers': '-1, 8', 'type': 'route'}\n",
      "-1\n",
      "{1: 'layer1-conv', 2: 'layer2-maxpool', 3: 'layer3-conv', 4: 'layer4-maxpool', 5: 'layer5-conv', 6: 'layer6-maxpool', 7: 'layer7-conv', 8: 'layer8-maxpool', 9: 'layer9-conv', 10: 'layer10-maxpool', 11: 'layer11-conv', 12: 'layer12-conv', 13: 'layer13-conv', 14: 'layer14-conv', 15: 'layer15-conv', 17: 'layer17-route', 18: 'layer18-conv', 19: 'layer19-upsample'}\n",
      "OrderedDict([('bottom', ['layer19-upsample', 'layer9-conv']), ('top', 'layer20-route'), ('name', 'layer20-route'), ('type', 'Concat')])\n",
      "20\n",
      "{'activation': 'leaky', 'stride': '1', 'pad': '1', 'filters': '256', 'batch_normalize': '1', 'type': 'convolutional', 'size': '3'}\n",
      "{'activation': 'linear', 'stride': '1', 'pad': '1', 'filters': '33', 'type': 'convolutional', 'size': '1'}\n",
      "{'jitter': '.3', 'anchors': '10,14,  23,27,  37,58,  81,82,  135,169,  344,319', 'random': '1', 'mask': '1,2,3', 'num': '6', 'classes': '6', 'ignore_thresh': '.7', 'truth_thresh': '1', 'type': 'yolo'}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':  \n",
    "    '''\n",
    "    cfgfile = sys.argv[1]   \n",
    "    weightfile = sys.argv[2]  \n",
    "    protofile = sys.argv[3]  \n",
    "    caffemodel = sys.argv[4]\n",
    "    '''\n",
    "    import datetime\n",
    "    \n",
    "    saved_prototxt = str(datetime.datetime.now()).split(' ')[-1] + cfgfile.split('/')[-1] + '.prototxt'\n",
    "    net_info = cfg2prototxt(cfgfile)    \n",
    "    save_prototxt(net_info, saved_prototxt)\n",
    "    sys.path.insert(0, '/data/ssd-caffe/new-yolov3-caffe/python')\n",
    "    del caffe\n",
    "    import caffe\n",
    "    #darknet2caffe(cfgfile, weightfile, protofile, caffemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0-rc3'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caffe.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
