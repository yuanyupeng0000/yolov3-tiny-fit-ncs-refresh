{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入pytorch这个包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "torch.set_printoptions(precision=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detect(nn.Module):\n",
    "    stride = None  # strides computed during build\n",
    "    export = False  # onnx export\n",
    "\n",
    "    def __init__(self, nc=80, anchors=(), ch=()):  # detection layer\n",
    "        super(Detect, self).__init__()\n",
    "        self.nc = nc  # number of classes 7\n",
    "        self.no = nc + 5  # number of outputs per anchor 12\n",
    "        self.nl = len(anchors)  # number of detection layers 3\n",
    "        self.na = len(anchors[0]) // 2  # number of anchors 3\n",
    "        self.grid = [torch.zeros(1)] * self.nl  # init grid\n",
    "        a = torch.tensor(anchors).float().view(self.nl, -1, 2)\n",
    "        self.register_buffer('anchors', a)  # shape(nl,na,2)\n",
    "        self.register_buffer('anchor_grid', a.clone().view(self.nl, 1, -1, 1, 1, 2))  # shape(nl,1,na,1,1,2)\n",
    "        self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, 1) for x in ch)  # output conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.copy()  # for profiling\n",
    "        z = []  # inference output\n",
    "        self.training |= self.export\n",
    "        for i in range(self.nl):\n",
    "            x[i] = self.m[i](x[i])  # conv\n",
    "            bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)\n",
    "            x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()\n",
    "\n",
    "            if not self.training:  # inference\n",
    "                if self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
    "                    self.grid[i] = self._make_grid(nx, ny).to(x[i].device)\n",
    "\n",
    "                y = x[i].sigmoid()\n",
    "                y[..., 0:2] = (y[..., 0:2] * 2. - 0.5 + self.grid[i].to(x[i].device)) * self.stride[i]  # xy\n",
    "                y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  # wh\n",
    "                z.append(y.view(bs, -1, self.no))\n",
    "\n",
    "        return x if self.training else (torch.cat(z, 1), x)\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_grid(nx=20, ny=20):\n",
    "        yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)])\n",
    "        return torch.stack((xv, yv), 2).view((1, 1, ny, nx, 2)).float()\n",
    "\n",
    "class MyDetect(nn.Module):\n",
    "    def __init__(self, nc=80, anchors=(), ch=()):  # detection layer\n",
    "        super(MyDetect, self).__init__()\n",
    "        self.nc = nc  # number of classes 7\n",
    "        self.no = nc + 5  # number of outputs per anchor 12\n",
    "        self.nl = len(anchors)  # number of detection layers 3\n",
    "        self.na = len(anchors[0]) // 2  # number of anchors 3\n",
    "        #self.conv_out_1 = nn.Conv2d(ch[0], self.no * self.na, 1)\n",
    "        #ones=torch.Tensor(np.ones([self.no * self.na, ch[0], 1, 1]))\n",
    "        '''\n",
    "        self.conv_out_1 = nn.Conv2d(ch[0], self.no * self.na, 1, 1, bias=True)\n",
    "        self.conv_out_1.weight = torch.nn.Parameter(torch.Tensor(np.ones([self.no * self.na, ch[0], 1, 1])))\n",
    "        self.conv_out_2 = nn.Conv2d(ch[1], self.no * self.na, 1, 1, bias=True)\n",
    "        self.conv_out_2.weight = torch.nn.Parameter(torch.Tensor(np.ones([self.no * self.na, ch[1], 1, 1])))\n",
    "        self.conv_out_3 = nn.Conv2d(512, 36, kernel_size=1, stride=1, bias=True)\n",
    "        self.conv_out_3.weight = torch.nn.Parameter(torch.Tensor(np.ones([36, 512, 1, 1])))\n",
    "        self.conv_out_3.bias = torch.nn.Parameter(torch.Tensor(np.zeros([36])))\n",
    "        self.m = nn.ModuleList([self.conv_out_1, self.conv_out_2, self.conv_out_3])  # output conv\n",
    "        '''\n",
    "        self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, 1) for x in ch)\n",
    "        for i, x in enumerate(ch):\n",
    "            self.m[i].weight = torch.nn.Parameter(torch.Tensor(np.ones([self.no * self.na, ch[i], 1, 1])))\n",
    "            self.m[i].bias = torch.nn.Parameter(torch.Tensor(np.zeros([self.no * self.na])))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.nl):\n",
    "            x[i] = self.m[i](x[i])  # conv\n",
    "        return x\n",
    "    def my_forward(self, x):\n",
    "        y = self.conv_out_3(x)  # conv\n",
    "        return y    \n",
    "\n",
    "class Concat(nn.Module):\n",
    "    # Concatenate a list of tensors along dimension\n",
    "    def __init__(self, dimension=1):\n",
    "        super(Concat, self).__init__()\n",
    "        self.d = dimension\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat(x, self.d)\n",
    "\n",
    "class SPP(nn.Module):\n",
    "    # Spatial pyramid pooling layer used in YOLOv3-SPP\n",
    "    def __init__(self, c1, c2, k=(5, 9, 13)):\n",
    "        super(SPP, self).__init__()\n",
    "        c_ = c1 // 2  # hidden channels\n",
    "        self.cv1 = Conv(c1, c_, 1, 1)\n",
    "        self.cv2 = Conv(c_ * (len(k) + 1), c2, 1, 1)\n",
    "        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) \\\n",
    "                                for x in k])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cv1(x)\n",
    "        return self.cv2(torch.cat([x] + [m(x) for m in self.m], 1))\n",
    "\n",
    "def autopad(k, p=None):  # kernel, padding\n",
    "    # Pad to 'same'\n",
    "    if p is None:\n",
    "        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad\n",
    "    return p\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    # Standard convolution\n",
    "    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)\n",
    "        ones=torch.Tensor(np.ones([c2,c1,k,k])) \n",
    "        # 先创建一个自定义权值的Tensor，这里为了方便将所有权值设为1\n",
    "        self.conv.weight=torch.nn.Parameter(ones) \n",
    "        # 把Tensor的值作为权值赋值给Conv层，这里需要先转为torch.nn.Parameter类型，否则将报错\n",
    "        print(self.conv.weight.size())\n",
    "        self.bn = nn.BatchNorm2d(c2)\n",
    "        ##self.act = nn.Hardswish() if act else nn.Identity()\n",
    "        self.act = nn.LeakyReLU(0.1, inplace=True) if act else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "        #return self.conv(x)\n",
    "\n",
    "    def fuseforward(self, x):\n",
    "        return self.act(self.conv(x))\n",
    "class Conv_(nn.Module):\n",
    "    # Standard convolution\n",
    "    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups\n",
    "        super(Conv_, self).__init__()\n",
    "        self.conv = nn.Conv2d(c1, c2, k, s, padding=autopad(k, p), groups=g, bias=False)\n",
    "        ones=torch.Tensor(np.ones([c2,c1,k,k])) \n",
    "        # 先创建一个自定义权值的Tensor，这里为了方便将所有权值设为1\n",
    "        self.conv.weight=torch.nn.Parameter(ones) \n",
    "        # 把Tensor的值作为权值赋值给Conv层，这里需要先转为torch.nn.Parameter类型，否则将报错\n",
    "        print(self.conv.weight.size())\n",
    "        self.bn = nn.BatchNorm2d(c2)\n",
    "        ##self.act = nn.Hardswish() if act else nn.Identity()\n",
    "        self.act = nn.LeakyReLU(0.1, inplace=True) if act else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "        #return self.conv(x)\n",
    "\n",
    "    def fuseforward(self, x):\n",
    "        return self.act(self.conv(x))\n",
    "\n",
    "class Focus(nn.Module):\n",
    "    # Focus wh information into c-space\n",
    "    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups\n",
    "        super(Focus, self).__init__()\n",
    "        self.conv = Conv(c1 * 4, c2, k, s, p, g, act)\n",
    "\n",
    "    def forward(self, x):  # x(b,c,w,h) -> y(b,4c,w/2,h/2)\n",
    "        return self.conv(torch.cat([x[..., ::2, ::2], x[..., 1::2, ::2], \\\n",
    "                                    x[..., ::2, 1::2], x[..., 1::2, 1::2]], 1))\n",
    "class Bottleneck(nn.Module):\n",
    "    # Standard bottleneck\n",
    "    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion\n",
    "        super(Bottleneck, self).__init__()\n",
    "        c_ = int(c2 * e)  # hidden channels\n",
    "        print(\"Into Bottlneck\")\n",
    "        self.cv1 = Conv(c1, c_, 1, 1)\n",
    "        self.cv2 = Conv(c_, c2, 3, 1, g=g)\n",
    "        self.add = shortcut and c1 == c2\n",
    "        print(\"Out Bottleneck\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        zz = x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n",
    "        return zz\n",
    "\n",
    "\n",
    "class BottleneckCSP(nn.Module):\n",
    "    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n",
    "    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n",
    "        super(BottleneckCSP, self).__init__()\n",
    "        c_ = int(c2 * e)  # hidden channels\n",
    "        self.cv1 = Conv(c1, c_, 1, 1)\n",
    "        self.cv2 = nn.Conv2d(c1, c_, 1, 1, bias=False)\n",
    "        ones=torch.Tensor(np.ones([c_,c1,1,1])) \n",
    "        # 先创建一个自定义权值的Tensor，这里为了方便将所有权值设为1\n",
    "        self.cv2.weight=torch.nn.Parameter(ones) \n",
    "        # 把Tensor的值作为权值赋值给Conv层，这里需要先转为torch.nn.Parameter类型，否则将报错\n",
    "        print(self.cv2.weight.size())\n",
    "        self.cv3 = nn.Conv2d(c_, c_, 1, 1, bias=False)\n",
    "        ones=torch.Tensor(np.ones([c_,c_,1,1]))\n",
    "        # 先创建一个自定义权值的Tensor，这里为了方便将所有权值设为1\n",
    "        self.cv3.weight=torch.nn.Parameter(ones) \n",
    "        # 把Tensor的值作为权值赋值给Conv层，这里需要先转为torch.nn.Parameter类型，否则将报错\n",
    "        print(self.cv3.weight.size())\n",
    "        self.cv4 = Conv(2 * c_, c2, 1, 1)\n",
    "        self.bn = nn.BatchNorm2d(2 * c_)  # applied to cat(cv2, cv3)\n",
    "        self.act = nn.LeakyReLU(0.1, inplace=True)\n",
    "        self.m = nn.Sequential(*[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.cv3(self.m(self.cv1(x)))\n",
    "        y2 = self.cv2(x)\n",
    "        return self.cv4(self.act(self.bn(torch.cat((y1, y2), dim=1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOV5S(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YOLOV5S, self).__init__()\n",
    "    def forward(self, x):\n",
    "        print(\"in yolov5s forward\")\n",
    "        \n",
    "        net_ = Focus(c1=3, c2=32, k=3)\n",
    "        y = net_(x)\n",
    "        #################################\n",
    "        conv1 = Conv(c1=32, c2=64, k=3, s=2)\n",
    "        out = conv1(y)\n",
    "        ################################\n",
    "        print(\"Into BottleneckCSP\")\n",
    "        BottleneckCSP_0 = BottleneckCSP(c1=64, c2=64)\n",
    "        out_botcsp = BottleneckCSP_0(out)\n",
    "        print(\"Leav BottleneckCSP\")\n",
    "        conv_d_2 = Conv(c1=64, c2=128, k=3, s=2)\n",
    "        out_conv_d_2 = conv_d_2(out_botcsp)\n",
    "        BottleneckCSP_1 = BottleneckCSP(c1=128, c2=128, n=3)\n",
    "        out_botcsp1 = BottleneckCSP_1(out_conv_d_2)\n",
    "        conv_d_3 = Conv(c1=128, c2=256, k=3, s=2)\n",
    "        out_conv_d_3 = conv_d_3(out_botcsp1)\n",
    "        BottleneckCSP_２ = BottleneckCSP(c1=256, c2=256, n=3)\n",
    "        out_botcsp2 = BottleneckCSP_２(out_conv_d_3)\n",
    "        conv_d_4 = Conv(c1=256, c2=512, k=3, s=2)\n",
    "        out_conv_d_4 = conv_d_4(out_botcsp2)\n",
    "        spp = SPP(512,512)\n",
    "        spp_out = spp(out_conv_d_4)\n",
    "        \n",
    "        BottleneckCSP_3 = BottleneckCSP(c1=512, c2=512, n=1, shortcut=False)\n",
    "        out_botcsp3 = BottleneckCSP_3(spp_out)\n",
    "        conv_5 = Conv(c1=512, c2=256)\n",
    "        out_conv_5 = conv_5(out_botcsp3)\n",
    "        upsample_1 = nn.modules.upsampling.Upsample(scale_factor=2,mode='nearest')\n",
    "        out_upsample_1 = upsample_1(out_conv_5)\n",
    "        concat_1 = Concat(dimension=1)\n",
    "        out_concat_1 = concat_1([out_upsample_1, out_botcsp2])\n",
    "        \n",
    "        BottleneckCSP_4 = BottleneckCSP(c1=512, c2=256, n=1, shortcut=False)\n",
    "        out_botcsp4 = BottleneckCSP_4(out_concat_1)        \n",
    "        conv_6 = Conv(c1=256, c2=128)\n",
    "        out_conv_6 = conv_6(out_botcsp4)\n",
    "        upsample_2 = nn.modules.upsampling.Upsample(scale_factor=2,mode='nearest')\n",
    "        out_upsample_2 = upsample_2(out_conv_6)\n",
    "        concat_2 = Concat(dimension=1)\n",
    "        out_concat_2 = concat_2([out_upsample_2, out_botcsp1])\n",
    "        \n",
    "        BottleneckCSP_5 = BottleneckCSP(c1=256, c2=128, n=1, shortcut=False)\n",
    "        out_botcsp5 = BottleneckCSP_5(out_concat_2)\n",
    "        conv_d_5 = Conv(c1=128, c2=128, k=3, s=2)\n",
    "        out_conv_d_5 = conv_d_5(out_botcsp5)\n",
    "        concat_3 = Concat(dimension=1)\n",
    "        out_concat_3 = concat_3([out_conv_d_5, out_conv_6])\n",
    "        \n",
    "        BottleneckCSP_6 = BottleneckCSP(c1=256, c2=256, n=1, shortcut=False)\n",
    "        out_botcsp6 = BottleneckCSP_6(out_concat_3)\n",
    "        conv_d_6 = Conv(c1=256, c2=256, k=3, s=2)\n",
    "        out_conv_d_6 = conv_d_6(out_botcsp6)\n",
    "        concat_4 = Concat(dimension=1)\n",
    "        out_concat_4 = concat_4([out_conv_d_6, out_conv_5])\n",
    "        \n",
    "        BottleneckCSP_7 = BottleneckCSP(c1=512, c2=512, n=1, shortcut=False)\n",
    "        out_botcsp7 = BottleneckCSP_7(out_concat_4)\n",
    "        \n",
    "        myDetect_all = MyDetect(nc=7, anchors=[[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], ch=[128, 256, 512])\n",
    "        detect_out = myDetect_all([out_botcsp5, out_botcsp6, out_botcsp7])\n",
    "                                \n",
    "        return detect_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.04313726, 0.05490196, 0.05490196,  ..., 0.05490196,\n",
      "           0.09019608, 0.02745098],\n",
      "          [0.05490196, 0.03921569, 0.12941177,  ..., 0.16470589,\n",
      "           0.16862746, 0.15294118],\n",
      "          [0.03529412, 0.05882353, 0.33725491,  ..., 0.12156863,\n",
      "           0.18431373, 0.20000000],\n",
      "          ...,\n",
      "          [0.21568628, 0.21568628, 0.21960784,  ..., 0.40784314,\n",
      "           0.41176471, 0.40000001],\n",
      "          [0.21960784, 0.21960784, 0.22352941,  ..., 0.41176471,\n",
      "           0.41568628, 0.40000001],\n",
      "          [0.20392157, 0.20784314, 0.21176471,  ..., 0.40392157,\n",
      "           0.41568628, 0.42352942]],\n",
      "\n",
      "         [[0.09411765, 0.09411765, 0.07058824,  ..., 0.26666668,\n",
      "           0.23921569, 0.14509805],\n",
      "          [0.10196079, 0.07450981, 0.14117648,  ..., 0.36078432,\n",
      "           0.32156864, 0.28235295],\n",
      "          [0.07843138, 0.09019608, 0.35686275,  ..., 0.27450982,\n",
      "           0.34509805, 0.36078432],\n",
      "          ...,\n",
      "          [0.23137255, 0.23137255, 0.23529412,  ..., 0.42352942,\n",
      "           0.42745098, 0.41568628],\n",
      "          [0.23529412, 0.23529412, 0.23921569,  ..., 0.42745098,\n",
      "           0.43137255, 0.41568628],\n",
      "          [0.21960784, 0.22352941, 0.22745098,  ..., 0.41960785,\n",
      "           0.43137255, 0.43921569]],\n",
      "\n",
      "         [[0.00000000, 0.00000000, 0.01568628,  ..., 0.31372550,\n",
      "           0.31372550, 0.23921569],\n",
      "          [0.01568628, 0.00000000, 0.09803922,  ..., 0.39607844,\n",
      "           0.38039216, 0.35686275],\n",
      "          [0.01568628, 0.03921569, 0.32941177,  ..., 0.29411766,\n",
      "           0.36862746, 0.38431373],\n",
      "          ...,\n",
      "          [0.24313726, 0.24313726, 0.24705882,  ..., 0.41960785,\n",
      "           0.42352942, 0.41176471],\n",
      "          [0.24705882, 0.24705882, 0.25098041,  ..., 0.42352942,\n",
      "           0.42745098, 0.41176471],\n",
      "          [0.23137255, 0.23529412, 0.23921569,  ..., 0.41568628,\n",
      "           0.42745098, 0.43529412]]]])\n",
      "in yolov5s forward\n",
      "torch.Size([32, 12, 3, 3])\n",
      "torch.Size([64, 32, 3, 3])\n",
      "Into BottleneckCSP\n",
      "torch.Size([32, 64, 1, 1])\n",
      "torch.Size([32, 64, 1, 1])\n",
      "torch.Size([32, 32, 1, 1])\n",
      "torch.Size([64, 64, 1, 1])\n",
      "Into Bottlneck\n",
      "torch.Size([32, 32, 1, 1])\n",
      "torch.Size([32, 32, 3, 3])\n",
      "Out Bottleneck\n",
      "Leav BottleneckCSP\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([64, 128, 1, 1])\n",
      "torch.Size([64, 128, 1, 1])\n",
      "torch.Size([64, 64, 1, 1])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "Into Bottlneck\n",
      "torch.Size([64, 64, 1, 1])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "Out Bottleneck\n",
      "Into Bottlneck\n",
      "torch.Size([64, 64, 1, 1])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "Out Bottleneck\n",
      "Into Bottlneck\n",
      "torch.Size([64, 64, 1, 1])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "Out Bottleneck\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([128, 256, 1, 1])\n",
      "torch.Size([128, 256, 1, 1])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([256, 256, 1, 1])\n",
      "Into Bottlneck\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "Out Bottleneck\n",
      "Into Bottlneck\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "Out Bottleneck\n",
      "Into Bottlneck\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "Out Bottleneck\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([512, 1024, 1, 1])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 256, 1, 1])\n",
      "torch.Size([512, 512, 1, 1])\n",
      "Into Bottlneck\n",
      "torch.Size([256, 256, 1, 1])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "Out Bottleneck\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([256, 256, 1, 1])\n",
      "Into Bottlneck\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "Out Bottleneck\n",
      "torch.Size([128, 256, 1, 1])\n",
      "torch.Size([64, 256, 1, 1])\n",
      "torch.Size([64, 256, 1, 1])\n",
      "torch.Size([64, 64, 1, 1])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "Into Bottlneck\n",
      "torch.Size([64, 64, 1, 1])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "Out Bottleneck\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 256, 1, 1])\n",
      "torch.Size([128, 256, 1, 1])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([256, 256, 1, 1])\n",
      "Into Bottlneck\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "Out Bottleneck\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 256, 1, 1])\n",
      "torch.Size([512, 512, 1, 1])\n",
      "Into Bottlneck\n",
      "torch.Size([256, 256, 1, 1])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "Out Bottleneck\n",
      "torch.Size([1, 36, 52, 52])\n",
      "tensor([[[[-3.63884854, -3.63939786, -3.63934112,  ..., -3.63945746,\n",
      "           -3.63945746, -3.63885331],\n",
      "          [-3.63942814, -3.63345170, -3.55715966,  ..., -3.64035678,\n",
      "           -3.64035678, -3.63946319],\n",
      "          [-3.63942695, -3.64013696, -3.64025211,  ..., -3.64035702,\n",
      "           -3.64035678, -3.63946319],\n",
      "          ...,\n",
      "          [-3.63945746, -3.64035678, -3.64035702,  ..., -3.64035702,\n",
      "           -3.64035678, -3.63946319],\n",
      "          [-3.63945746, -3.64035678, -3.64035678,  ..., -3.64035678,\n",
      "           -3.64035678, -3.63945889],\n",
      "          [-3.63885331, -3.63945889, -3.63946319,  ..., -3.63946319,\n",
      "           -3.63945889, -3.63885474]],\n",
      "\n",
      "         [[-3.63884854, -3.63939786, -3.63934112,  ..., -3.63945746,\n",
      "           -3.63945746, -3.63885331],\n",
      "          [-3.63942814, -3.63345170, -3.55715966,  ..., -3.64035678,\n",
      "           -3.64035678, -3.63946319],\n",
      "          [-3.63942695, -3.64013696, -3.64025211,  ..., -3.64035702,\n",
      "           -3.64035678, -3.63946319],\n",
      "          ...,\n",
      "          [-3.63945746, -3.64035678, -3.64035702,  ..., -3.64035702,\n",
      "           -3.64035678, -3.63946319],\n",
      "          [-3.63945746, -3.64035678, -3.64035678,  ..., -3.64035678,\n",
      "           -3.64035678, -3.63945889],\n",
      "          [-3.63885331, -3.63945889, -3.63946319,  ..., -3.63946319,\n",
      "           -3.63945889, -3.63885474]],\n",
      "\n",
      "         [[-3.63884854, -3.63939786, -3.63934112,  ..., -3.63945746,\n",
      "           -3.63945746, -3.63885331],\n",
      "          [-3.63942814, -3.63345170, -3.55715966,  ..., -3.64035678,\n",
      "           -3.64035678, -3.63946319],\n",
      "          [-3.63942695, -3.64013696, -3.64025211,  ..., -3.64035702,\n",
      "           -3.64035678, -3.63946319],\n",
      "          ...,\n",
      "          [-3.63945746, -3.64035678, -3.64035702,  ..., -3.64035702,\n",
      "           -3.64035678, -3.63946319],\n",
      "          [-3.63945746, -3.64035678, -3.64035678,  ..., -3.64035678,\n",
      "           -3.64035678, -3.63945889],\n",
      "          [-3.63885331, -3.63945889, -3.63946319,  ..., -3.63946319,\n",
      "           -3.63945889, -3.63885474]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.63884854, -3.63939786, -3.63934112,  ..., -3.63945746,\n",
      "           -3.63945746, -3.63885331],\n",
      "          [-3.63942814, -3.63345170, -3.55715966,  ..., -3.64035678,\n",
      "           -3.64035678, -3.63946319],\n",
      "          [-3.63942695, -3.64013696, -3.64025211,  ..., -3.64035702,\n",
      "           -3.64035678, -3.63946319],\n",
      "          ...,\n",
      "          [-3.63945746, -3.64035678, -3.64035702,  ..., -3.64035702,\n",
      "           -3.64035678, -3.63946319],\n",
      "          [-3.63945746, -3.64035678, -3.64035678,  ..., -3.64035678,\n",
      "           -3.64035678, -3.63945889],\n",
      "          [-3.63885331, -3.63945889, -3.63946319,  ..., -3.63946319,\n",
      "           -3.63945889, -3.63885474]],\n",
      "\n",
      "         [[-3.63884854, -3.63939786, -3.63934112,  ..., -3.63945746,\n",
      "           -3.63945746, -3.63885331],\n",
      "          [-3.63942814, -3.63345170, -3.55715966,  ..., -3.64035678,\n",
      "           -3.64035678, -3.63946319],\n",
      "          [-3.63942695, -3.64013696, -3.64025211,  ..., -3.64035702,\n",
      "           -3.64035678, -3.63946319],\n",
      "          ...,\n",
      "          [-3.63945746, -3.64035678, -3.64035702,  ..., -3.64035702,\n",
      "           -3.64035678, -3.63946319],\n",
      "          [-3.63945746, -3.64035678, -3.64035678,  ..., -3.64035678,\n",
      "           -3.64035678, -3.63945889],\n",
      "          [-3.63885331, -3.63945889, -3.63946319,  ..., -3.63946319,\n",
      "           -3.63945889, -3.63885474]],\n",
      "\n",
      "         [[-3.63884854, -3.63939786, -3.63934112,  ..., -3.63945746,\n",
      "           -3.63945746, -3.63885331],\n",
      "          [-3.63942814, -3.63345170, -3.55715966,  ..., -3.64035678,\n",
      "           -3.64035678, -3.63946319],\n",
      "          [-3.63942695, -3.64013696, -3.64025211,  ..., -3.64035702,\n",
      "           -3.64035678, -3.63946319],\n",
      "          ...,\n",
      "          [-3.63945746, -3.64035678, -3.64035702,  ..., -3.64035702,\n",
      "           -3.64035678, -3.63946319],\n",
      "          [-3.63945746, -3.64035678, -3.64035678,  ..., -3.64035678,\n",
      "           -3.64035678, -3.63945889],\n",
      "          [-3.63885331, -3.63945889, -3.63946319,  ..., -3.63946319,\n",
      "           -3.63945889, -3.63885474]]]], grad_fn=<MkldnnConvolutionBackward>)\n",
      "torch.Size([1, 36, 26, 26])\n",
      "tensor([[[[-6.67760754, -6.67926407, -6.67927408,  ..., -6.67927408,\n",
      "           -6.67927408, -6.67815781],\n",
      "          [-6.67927408, -6.68177748, -6.68178082,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67927408, -6.68178082, -6.68178082,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          ...,\n",
      "          [-6.67927408, -6.68178082, -6.68151903,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67927408, -6.68178082, -6.68123055,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67815781, -6.68011093, -6.68009996,  ..., -6.68011093,\n",
      "           -6.68011093, -6.67897224]],\n",
      "\n",
      "         [[-6.67760754, -6.67926407, -6.67927408,  ..., -6.67927408,\n",
      "           -6.67927408, -6.67815781],\n",
      "          [-6.67927408, -6.68177748, -6.68178082,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67927408, -6.68178082, -6.68178082,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          ...,\n",
      "          [-6.67927408, -6.68178082, -6.68151903,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67927408, -6.68178082, -6.68123055,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67815781, -6.68011093, -6.68009996,  ..., -6.68011093,\n",
      "           -6.68011093, -6.67897224]],\n",
      "\n",
      "         [[-6.67760754, -6.67926407, -6.67927408,  ..., -6.67927408,\n",
      "           -6.67927408, -6.67815781],\n",
      "          [-6.67927408, -6.68177748, -6.68178082,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67927408, -6.68178082, -6.68178082,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          ...,\n",
      "          [-6.67927408, -6.68178082, -6.68151903,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67927408, -6.68178082, -6.68123055,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67815781, -6.68011093, -6.68009996,  ..., -6.68011093,\n",
      "           -6.68011093, -6.67897224]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.67760754, -6.67926407, -6.67927408,  ..., -6.67927408,\n",
      "           -6.67927408, -6.67815781],\n",
      "          [-6.67927408, -6.68177748, -6.68178082,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67927408, -6.68178082, -6.68178082,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          ...,\n",
      "          [-6.67927408, -6.68178082, -6.68151903,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67927408, -6.68178082, -6.68123055,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67815781, -6.68011093, -6.68009996,  ..., -6.68011093,\n",
      "           -6.68011093, -6.67897224]],\n",
      "\n",
      "         [[-6.67760754, -6.67926407, -6.67927408,  ..., -6.67927408,\n",
      "           -6.67927408, -6.67815781],\n",
      "          [-6.67927408, -6.68177748, -6.68178082,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67927408, -6.68178082, -6.68178082,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          ...,\n",
      "          [-6.67927408, -6.68178082, -6.68151903,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67927408, -6.68178082, -6.68123055,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67815781, -6.68011093, -6.68009996,  ..., -6.68011093,\n",
      "           -6.68011093, -6.67897224]],\n",
      "\n",
      "         [[-6.67760754, -6.67926407, -6.67927408,  ..., -6.67927408,\n",
      "           -6.67927408, -6.67815781],\n",
      "          [-6.67927408, -6.68177748, -6.68178082,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67927408, -6.68178082, -6.68178082,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          ...,\n",
      "          [-6.67927408, -6.68178082, -6.68151903,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67927408, -6.68178082, -6.68123055,  ..., -6.68178082,\n",
      "           -6.68178082, -6.68011093],\n",
      "          [-6.67815781, -6.68011093, -6.68009996,  ..., -6.68011093,\n",
      "           -6.68011093, -6.67897224]]]], grad_fn=<MkldnnConvolutionBackward>)\n",
      "torch.Size([1, 36, 13, 13])\n",
      "tensor([[[[-16.96996307, -16.97447968, -16.97447968,  ..., -16.97447968,\n",
      "           -16.97447968, -16.97116280],\n",
      "          [-16.97445107, -16.98122978, -16.98122978,  ..., -16.98122978,\n",
      "           -16.98122978, -16.97622681],\n",
      "          [-16.97436714, -16.98119926, -16.98119926,  ..., -16.98119545,\n",
      "           -16.98119545, -16.97618103],\n",
      "          ...,\n",
      "          [-16.97422791, -16.98096466, -16.97427940,  ..., -16.97303200,\n",
      "           -16.98097992, -16.97598648],\n",
      "          [-16.97422791, -16.98096466, -16.97433662,  ..., -16.97461128,\n",
      "           -16.98098564, -16.97598648],\n",
      "          [-16.97085571, -16.97596550, -16.96934509,  ..., -16.97533989,\n",
      "           -16.97598648, -16.97265625]],\n",
      "\n",
      "         [[-16.96996307, -16.97447968, -16.97447968,  ..., -16.97447968,\n",
      "           -16.97447968, -16.97116280],\n",
      "          [-16.97445107, -16.98122978, -16.98122978,  ..., -16.98122978,\n",
      "           -16.98122978, -16.97622681],\n",
      "          [-16.97436714, -16.98119926, -16.98119926,  ..., -16.98119545,\n",
      "           -16.98119545, -16.97618103],\n",
      "          ...,\n",
      "          [-16.97422791, -16.98096466, -16.97427940,  ..., -16.97303200,\n",
      "           -16.98097992, -16.97598648],\n",
      "          [-16.97422791, -16.98096466, -16.97433662,  ..., -16.97461128,\n",
      "           -16.98098564, -16.97598648],\n",
      "          [-16.97085571, -16.97596550, -16.96934509,  ..., -16.97533989,\n",
      "           -16.97598648, -16.97265625]],\n",
      "\n",
      "         [[-16.96996307, -16.97447968, -16.97447968,  ..., -16.97447968,\n",
      "           -16.97447968, -16.97116280],\n",
      "          [-16.97445107, -16.98122978, -16.98122978,  ..., -16.98122978,\n",
      "           -16.98122978, -16.97622681],\n",
      "          [-16.97436714, -16.98119926, -16.98119926,  ..., -16.98119545,\n",
      "           -16.98119545, -16.97618103],\n",
      "          ...,\n",
      "          [-16.97422791, -16.98096466, -16.97427940,  ..., -16.97303200,\n",
      "           -16.98097992, -16.97598648],\n",
      "          [-16.97422791, -16.98096466, -16.97433662,  ..., -16.97461128,\n",
      "           -16.98098564, -16.97598648],\n",
      "          [-16.97085571, -16.97596550, -16.96934509,  ..., -16.97533989,\n",
      "           -16.97598648, -16.97265625]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-16.96996307, -16.97447968, -16.97447968,  ..., -16.97447968,\n",
      "           -16.97447968, -16.97116280],\n",
      "          [-16.97445107, -16.98122978, -16.98122978,  ..., -16.98122978,\n",
      "           -16.98122978, -16.97622681],\n",
      "          [-16.97436714, -16.98119926, -16.98119926,  ..., -16.98119545,\n",
      "           -16.98119545, -16.97618103],\n",
      "          ...,\n",
      "          [-16.97422791, -16.98096466, -16.97427940,  ..., -16.97303200,\n",
      "           -16.98097992, -16.97598648],\n",
      "          [-16.97422791, -16.98096466, -16.97433662,  ..., -16.97461128,\n",
      "           -16.98098564, -16.97598648],\n",
      "          [-16.97085571, -16.97596550, -16.96934509,  ..., -16.97533989,\n",
      "           -16.97598648, -16.97265625]],\n",
      "\n",
      "         [[-16.96996307, -16.97447968, -16.97447968,  ..., -16.97447968,\n",
      "           -16.97447968, -16.97116280],\n",
      "          [-16.97445107, -16.98122978, -16.98122978,  ..., -16.98122978,\n",
      "           -16.98122978, -16.97622681],\n",
      "          [-16.97436714, -16.98119926, -16.98119926,  ..., -16.98119545,\n",
      "           -16.98119545, -16.97618103],\n",
      "          ...,\n",
      "          [-16.97422791, -16.98096466, -16.97427940,  ..., -16.97303200,\n",
      "           -16.98097992, -16.97598648],\n",
      "          [-16.97422791, -16.98096466, -16.97433662,  ..., -16.97461128,\n",
      "           -16.98098564, -16.97598648],\n",
      "          [-16.97085571, -16.97596550, -16.96934509,  ..., -16.97533989,\n",
      "           -16.97598648, -16.97265625]],\n",
      "\n",
      "         [[-16.96996307, -16.97447968, -16.97447968,  ..., -16.97447968,\n",
      "           -16.97447968, -16.97116280],\n",
      "          [-16.97445107, -16.98122978, -16.98122978,  ..., -16.98122978,\n",
      "           -16.98122978, -16.97622681],\n",
      "          [-16.97436714, -16.98119926, -16.98119926,  ..., -16.98119545,\n",
      "           -16.98119545, -16.97618103],\n",
      "          ...,\n",
      "          [-16.97422791, -16.98096466, -16.97427940,  ..., -16.97303200,\n",
      "           -16.98097992, -16.97598648],\n",
      "          [-16.97422791, -16.98096466, -16.97433662,  ..., -16.97461128,\n",
      "           -16.98098564, -16.97598648],\n",
      "          [-16.97085571, -16.97596550, -16.96934509,  ..., -16.97533989,\n",
      "           -16.97598648, -16.97265625]]]], grad_fn=<MkldnnConvolutionBackward>)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img_file = '/data/github_repos/yolov3-tiny-fit-ncs/ncs/standard_size_416_persons.jpg'\n",
    "cv2.__version__\n",
    "img = cv2.imread(img_file) ###BGR\n",
    "resized_img = cv2.resize(img, (416,416))\n",
    "resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB) # cv2默认为bgr顺序\n",
    "img_ = np.transpose(resized_img, (2, 0, 1))\n",
    "#print(img_.shape)\n",
    "#print(img_)\n",
    "normerlized = img_/255.0\n",
    "input_t = torchvision.transforms.functional.to_tensor(resized_img)\n",
    "input_t = input_t.unsqueeze(0)\n",
    "print(input_t)\n",
    "#print(normerlized)\n",
    "net = YOLOV5S()\n",
    "output = net(input_t)\n",
    "for o in output:\n",
    "    print(o.size())\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
