7767517
351 378
Input            data             0 1 data 0=416 1=416 2=3
Convolution      layer1-conv      1 1 data layer1-conv 0=32 1=3 2=1 3=1 4=1 5=0 6=864
BatchNorm        layer1-bn        1 1 layer1-conv layer1-conv_layer1-bn 0=32
Scale            layer1-scale     1 1 layer1-conv_layer1-bn layer1-conv_layer1-scale 0=32 1=1
ReLU             layer1-act       1 1 layer1-conv_layer1-scale layer1-conv_layer1-act 0=0.100000
Convolution      layer2-conv      1 1 layer1-conv_layer1-act layer2-conv 0=64 1=3 2=1 3=2 4=1 5=0 6=18432
BatchNorm        layer2-bn        1 1 layer2-conv layer2-conv_layer2-bn 0=64
Scale            layer2-scale     1 1 layer2-conv_layer2-bn layer2-conv_layer2-scale 0=64 1=1
ReLU             layer2-act       1 1 layer2-conv_layer2-scale layer2-conv_layer2-act 0=0.100000
Split            splitncnn_0      1 2 layer2-conv_layer2-act layer2-conv_layer2-act_splitncnn_0 layer2-conv_layer2-act_splitncnn_1
Convolution      layer3-conv      1 1 layer2-conv_layer2-act_splitncnn_1 layer3-conv 0=32 1=1 2=1 3=1 4=0 5=0 6=2048
BatchNorm        layer3-bn        1 1 layer3-conv layer3-conv_layer3-bn 0=32
Scale            layer3-scale     1 1 layer3-conv_layer3-bn layer3-conv_layer3-scale 0=32 1=1
ReLU             layer3-act       1 1 layer3-conv_layer3-scale layer3-conv_layer3-act 0=0.100000
Convolution      layer4-conv      1 1 layer3-conv_layer3-act layer4-conv 0=64 1=3 2=1 3=1 4=1 5=0 6=18432
BatchNorm        layer4-bn        1 1 layer4-conv layer4-conv_layer4-bn 0=64
Scale            layer4-scale     1 1 layer4-conv_layer4-bn layer4-conv_layer4-scale 0=64 1=1
ReLU             layer4-act       1 1 layer4-conv_layer4-scale layer4-conv_layer4-act 0=0.100000
Eltwise          layer5-shortcut  2 1 layer2-conv_layer2-act_splitncnn_0 layer4-conv_layer4-act layer5-shortcut 0=1 -23301=0
Convolution      layer6-conv      1 1 layer5-shortcut layer6-conv 0=128 1=3 2=1 3=2 4=1 5=0 6=73728
BatchNorm        layer6-bn        1 1 layer6-conv layer6-conv_layer6-bn 0=128
Scale            layer6-scale     1 1 layer6-conv_layer6-bn layer6-conv_layer6-scale 0=128 1=1
ReLU             layer6-act       1 1 layer6-conv_layer6-scale layer6-conv_layer6-act 0=0.100000
Split            splitncnn_1      1 2 layer6-conv_layer6-act layer6-conv_layer6-act_splitncnn_0 layer6-conv_layer6-act_splitncnn_1
Convolution      layer7-conv      1 1 layer6-conv_layer6-act_splitncnn_1 layer7-conv 0=64 1=1 2=1 3=1 4=0 5=0 6=8192
BatchNorm        layer7-bn        1 1 layer7-conv layer7-conv_layer7-bn 0=64
Scale            layer7-scale     1 1 layer7-conv_layer7-bn layer7-conv_layer7-scale 0=64 1=1
ReLU             layer7-act       1 1 layer7-conv_layer7-scale layer7-conv_layer7-act 0=0.100000
Convolution      layer8-conv      1 1 layer7-conv_layer7-act layer8-conv 0=128 1=3 2=1 3=1 4=1 5=0 6=73728
BatchNorm        layer8-bn        1 1 layer8-conv layer8-conv_layer8-bn 0=128
Scale            layer8-scale     1 1 layer8-conv_layer8-bn layer8-conv_layer8-scale 0=128 1=1
ReLU             layer8-act       1 1 layer8-conv_layer8-scale layer8-conv_layer8-act 0=0.100000
Eltwise          layer9-shortcut  2 1 layer6-conv_layer6-act_splitncnn_0 layer8-conv_layer8-act layer9-shortcut 0=1 -23301=0
Split            splitncnn_2      1 2 layer9-shortcut layer9-shortcut_splitncnn_0 layer9-shortcut_splitncnn_1
Convolution      layer10-conv     1 1 layer9-shortcut_splitncnn_1 layer10-conv 0=64 1=1 2=1 3=1 4=0 5=0 6=8192
BatchNorm        layer10-bn       1 1 layer10-conv layer10-conv_layer10-bn 0=64
Scale            layer10-scale    1 1 layer10-conv_layer10-bn layer10-conv_layer10-scale 0=64 1=1
ReLU             layer10-act      1 1 layer10-conv_layer10-scale layer10-conv_layer10-act 0=0.100000
Convolution      layer11-conv     1 1 layer10-conv_layer10-act layer11-conv 0=128 1=3 2=1 3=1 4=1 5=0 6=73728
BatchNorm        layer11-bn       1 1 layer11-conv layer11-conv_layer11-bn 0=128
Scale            layer11-scale    1 1 layer11-conv_layer11-bn layer11-conv_layer11-scale 0=128 1=1
ReLU             layer11-act      1 1 layer11-conv_layer11-scale layer11-conv_layer11-act 0=0.100000
Eltwise          layer12-shortcut 2 1 layer9-shortcut_splitncnn_0 layer11-conv_layer11-act layer12-shortcut 0=1 -23301=0
Convolution      layer13-conv     1 1 layer12-shortcut layer13-conv 0=256 1=3 2=1 3=2 4=1 5=0 6=294912
BatchNorm        layer13-bn       1 1 layer13-conv layer13-conv_layer13-bn 0=256
Scale            layer13-scale    1 1 layer13-conv_layer13-bn layer13-conv_layer13-scale 0=256 1=1
ReLU             layer13-act      1 1 layer13-conv_layer13-scale layer13-conv_layer13-act 0=0.100000
Split            splitncnn_3      1 2 layer13-conv_layer13-act layer13-conv_layer13-act_splitncnn_0 layer13-conv_layer13-act_splitncnn_1
Convolution      layer14-conv     1 1 layer13-conv_layer13-act_splitncnn_1 layer14-conv 0=128 1=1 2=1 3=1 4=0 5=0 6=32768
BatchNorm        layer14-bn       1 1 layer14-conv layer14-conv_layer14-bn 0=128
Scale            layer14-scale    1 1 layer14-conv_layer14-bn layer14-conv_layer14-scale 0=128 1=1
ReLU             layer14-act      1 1 layer14-conv_layer14-scale layer14-conv_layer14-act 0=0.100000
Convolution      layer15-conv     1 1 layer14-conv_layer14-act layer15-conv 0=256 1=3 2=1 3=1 4=1 5=0 6=294912
BatchNorm        layer15-bn       1 1 layer15-conv layer15-conv_layer15-bn 0=256
Scale            layer15-scale    1 1 layer15-conv_layer15-bn layer15-conv_layer15-scale 0=256 1=1
ReLU             layer15-act      1 1 layer15-conv_layer15-scale layer15-conv_layer15-act 0=0.100000
Eltwise          layer16-shortcut 2 1 layer13-conv_layer13-act_splitncnn_0 layer15-conv_layer15-act layer16-shortcut 0=1 -23301=0
Split            splitncnn_4      1 2 layer16-shortcut layer16-shortcut_splitncnn_0 layer16-shortcut_splitncnn_1
Convolution      layer17-conv     1 1 layer16-shortcut_splitncnn_1 layer17-conv 0=128 1=1 2=1 3=1 4=0 5=0 6=32768
BatchNorm        layer17-bn       1 1 layer17-conv layer17-conv_layer17-bn 0=128
Scale            layer17-scale    1 1 layer17-conv_layer17-bn layer17-conv_layer17-scale 0=128 1=1
ReLU             layer17-act      1 1 layer17-conv_layer17-scale layer17-conv_layer17-act 0=0.100000
Convolution      layer18-conv     1 1 layer17-conv_layer17-act layer18-conv 0=256 1=3 2=1 3=1 4=1 5=0 6=294912
BatchNorm        layer18-bn       1 1 layer18-conv layer18-conv_layer18-bn 0=256
Scale            layer18-scale    1 1 layer18-conv_layer18-bn layer18-conv_layer18-scale 0=256 1=1
ReLU             layer18-act      1 1 layer18-conv_layer18-scale layer18-conv_layer18-act 0=0.100000
Eltwise          layer19-shortcut 2 1 layer16-shortcut_splitncnn_0 layer18-conv_layer18-act layer19-shortcut 0=1 -23301=0
Split            splitncnn_5      1 2 layer19-shortcut layer19-shortcut_splitncnn_0 layer19-shortcut_splitncnn_1
Convolution      layer20-conv     1 1 layer19-shortcut_splitncnn_1 layer20-conv 0=128 1=1 2=1 3=1 4=0 5=0 6=32768
BatchNorm        layer20-bn       1 1 layer20-conv layer20-conv_layer20-bn 0=128
Scale            layer20-scale    1 1 layer20-conv_layer20-bn layer20-conv_layer20-scale 0=128 1=1
ReLU             layer20-act      1 1 layer20-conv_layer20-scale layer20-conv_layer20-act 0=0.100000
Convolution      layer21-conv     1 1 layer20-conv_layer20-act layer21-conv 0=256 1=3 2=1 3=1 4=1 5=0 6=294912
BatchNorm        layer21-bn       1 1 layer21-conv layer21-conv_layer21-bn 0=256
Scale            layer21-scale    1 1 layer21-conv_layer21-bn layer21-conv_layer21-scale 0=256 1=1
ReLU             layer21-act      1 1 layer21-conv_layer21-scale layer21-conv_layer21-act 0=0.100000
Eltwise          layer22-shortcut 2 1 layer19-shortcut_splitncnn_0 layer21-conv_layer21-act layer22-shortcut 0=1 -23301=0
Split            splitncnn_6      1 2 layer22-shortcut layer22-shortcut_splitncnn_0 layer22-shortcut_splitncnn_1
Convolution      layer23-conv     1 1 layer22-shortcut_splitncnn_1 layer23-conv 0=128 1=1 2=1 3=1 4=0 5=0 6=32768
BatchNorm        layer23-bn       1 1 layer23-conv layer23-conv_layer23-bn 0=128
Scale            layer23-scale    1 1 layer23-conv_layer23-bn layer23-conv_layer23-scale 0=128 1=1
ReLU             layer23-act      1 1 layer23-conv_layer23-scale layer23-conv_layer23-act 0=0.100000
Convolution      layer24-conv     1 1 layer23-conv_layer23-act layer24-conv 0=256 1=3 2=1 3=1 4=1 5=0 6=294912
BatchNorm        layer24-bn       1 1 layer24-conv layer24-conv_layer24-bn 0=256
Scale            layer24-scale    1 1 layer24-conv_layer24-bn layer24-conv_layer24-scale 0=256 1=1
ReLU             layer24-act      1 1 layer24-conv_layer24-scale layer24-conv_layer24-act 0=0.100000
Eltwise          layer25-shortcut 2 1 layer22-shortcut_splitncnn_0 layer24-conv_layer24-act layer25-shortcut 0=1 -23301=0
Split            splitncnn_7      1 2 layer25-shortcut layer25-shortcut_splitncnn_0 layer25-shortcut_splitncnn_1
Convolution      layer26-conv     1 1 layer25-shortcut_splitncnn_1 layer26-conv 0=128 1=1 2=1 3=1 4=0 5=0 6=32768
BatchNorm        layer26-bn       1 1 layer26-conv layer26-conv_layer26-bn 0=128
Scale            layer26-scale    1 1 layer26-conv_layer26-bn layer26-conv_layer26-scale 0=128 1=1
ReLU             layer26-act      1 1 layer26-conv_layer26-scale layer26-conv_layer26-act 0=0.100000
Convolution      layer27-conv     1 1 layer26-conv_layer26-act layer27-conv 0=256 1=3 2=1 3=1 4=1 5=0 6=294912
BatchNorm        layer27-bn       1 1 layer27-conv layer27-conv_layer27-bn 0=256
Scale            layer27-scale    1 1 layer27-conv_layer27-bn layer27-conv_layer27-scale 0=256 1=1
ReLU             layer27-act      1 1 layer27-conv_layer27-scale layer27-conv_layer27-act 0=0.100000
Eltwise          layer28-shortcut 2 1 layer25-shortcut_splitncnn_0 layer27-conv_layer27-act layer28-shortcut 0=1 -23301=0
Split            splitncnn_8      1 2 layer28-shortcut layer28-shortcut_splitncnn_0 layer28-shortcut_splitncnn_1
Convolution      layer29-conv     1 1 layer28-shortcut_splitncnn_1 layer29-conv 0=128 1=1 2=1 3=1 4=0 5=0 6=32768
BatchNorm        layer29-bn       1 1 layer29-conv layer29-conv_layer29-bn 0=128
Scale            layer29-scale    1 1 layer29-conv_layer29-bn layer29-conv_layer29-scale 0=128 1=1
ReLU             layer29-act      1 1 layer29-conv_layer29-scale layer29-conv_layer29-act 0=0.100000
Convolution      layer30-conv     1 1 layer29-conv_layer29-act layer30-conv 0=256 1=3 2=1 3=1 4=1 5=0 6=294912
BatchNorm        layer30-bn       1 1 layer30-conv layer30-conv_layer30-bn 0=256
Scale            layer30-scale    1 1 layer30-conv_layer30-bn layer30-conv_layer30-scale 0=256 1=1
ReLU             layer30-act      1 1 layer30-conv_layer30-scale layer30-conv_layer30-act 0=0.100000
Eltwise          layer31-shortcut 2 1 layer28-shortcut_splitncnn_0 layer30-conv_layer30-act layer31-shortcut 0=1 -23301=0
Split            splitncnn_9      1 2 layer31-shortcut layer31-shortcut_splitncnn_0 layer31-shortcut_splitncnn_1
Convolution      layer32-conv     1 1 layer31-shortcut_splitncnn_1 layer32-conv 0=128 1=1 2=1 3=1 4=0 5=0 6=32768
BatchNorm        layer32-bn       1 1 layer32-conv layer32-conv_layer32-bn 0=128
Scale            layer32-scale    1 1 layer32-conv_layer32-bn layer32-conv_layer32-scale 0=128 1=1
ReLU             layer32-act      1 1 layer32-conv_layer32-scale layer32-conv_layer32-act 0=0.100000
Convolution      layer33-conv     1 1 layer32-conv_layer32-act layer33-conv 0=256 1=3 2=1 3=1 4=1 5=0 6=294912
BatchNorm        layer33-bn       1 1 layer33-conv layer33-conv_layer33-bn 0=256
Scale            layer33-scale    1 1 layer33-conv_layer33-bn layer33-conv_layer33-scale 0=256 1=1
ReLU             layer33-act      1 1 layer33-conv_layer33-scale layer33-conv_layer33-act 0=0.100000
Eltwise          layer34-shortcut 2 1 layer31-shortcut_splitncnn_0 layer33-conv_layer33-act layer34-shortcut 0=1 -23301=0
Split            splitncnn_10     1 2 layer34-shortcut layer34-shortcut_splitncnn_0 layer34-shortcut_splitncnn_1
Convolution      layer35-conv     1 1 layer34-shortcut_splitncnn_1 layer35-conv 0=128 1=1 2=1 3=1 4=0 5=0 6=32768
BatchNorm        layer35-bn       1 1 layer35-conv layer35-conv_layer35-bn 0=128
Scale            layer35-scale    1 1 layer35-conv_layer35-bn layer35-conv_layer35-scale 0=128 1=1
ReLU             layer35-act      1 1 layer35-conv_layer35-scale layer35-conv_layer35-act 0=0.100000
Convolution      layer36-conv     1 1 layer35-conv_layer35-act layer36-conv 0=256 1=3 2=1 3=1 4=1 5=0 6=294912
BatchNorm        layer36-bn       1 1 layer36-conv layer36-conv_layer36-bn 0=256
Scale            layer36-scale    1 1 layer36-conv_layer36-bn layer36-conv_layer36-scale 0=256 1=1
ReLU             layer36-act      1 1 layer36-conv_layer36-scale layer36-conv_layer36-act 0=0.100000
Eltwise          layer37-shortcut 2 1 layer34-shortcut_splitncnn_0 layer36-conv_layer36-act layer37-shortcut 0=1 -23301=0
Split            splitncnn_11     1 2 layer37-shortcut layer37-shortcut_splitncnn_0 layer37-shortcut_splitncnn_1
Convolution      layer38-conv     1 1 layer37-shortcut_splitncnn_1 layer38-conv 0=512 1=3 2=1 3=2 4=1 5=0 6=1179648
BatchNorm        layer38-bn       1 1 layer38-conv layer38-conv_layer38-bn 0=512
Scale            layer38-scale    1 1 layer38-conv_layer38-bn layer38-conv_layer38-scale 0=512 1=1
ReLU             layer38-act      1 1 layer38-conv_layer38-scale layer38-conv_layer38-act 0=0.100000
Split            splitncnn_12     1 2 layer38-conv_layer38-act layer38-conv_layer38-act_splitncnn_0 layer38-conv_layer38-act_splitncnn_1
Convolution      layer39-conv     1 1 layer38-conv_layer38-act_splitncnn_1 layer39-conv 0=256 1=1 2=1 3=1 4=0 5=0 6=131072
BatchNorm        layer39-bn       1 1 layer39-conv layer39-conv_layer39-bn 0=256
Scale            layer39-scale    1 1 layer39-conv_layer39-bn layer39-conv_layer39-scale 0=256 1=1
ReLU             layer39-act      1 1 layer39-conv_layer39-scale layer39-conv_layer39-act 0=0.100000
Convolution      layer40-conv     1 1 layer39-conv_layer39-act layer40-conv 0=512 1=3 2=1 3=1 4=1 5=0 6=1179648
BatchNorm        layer40-bn       1 1 layer40-conv layer40-conv_layer40-bn 0=512
Scale            layer40-scale    1 1 layer40-conv_layer40-bn layer40-conv_layer40-scale 0=512 1=1
ReLU             layer40-act      1 1 layer40-conv_layer40-scale layer40-conv_layer40-act 0=0.100000
Eltwise          layer41-shortcut 2 1 layer38-conv_layer38-act_splitncnn_0 layer40-conv_layer40-act layer41-shortcut 0=1 -23301=0
Split            splitncnn_13     1 2 layer41-shortcut layer41-shortcut_splitncnn_0 layer41-shortcut_splitncnn_1
Convolution      layer42-conv     1 1 layer41-shortcut_splitncnn_1 layer42-conv 0=256 1=1 2=1 3=1 4=0 5=0 6=131072
BatchNorm        layer42-bn       1 1 layer42-conv layer42-conv_layer42-bn 0=256
Scale            layer42-scale    1 1 layer42-conv_layer42-bn layer42-conv_layer42-scale 0=256 1=1
ReLU             layer42-act      1 1 layer42-conv_layer42-scale layer42-conv_layer42-act 0=0.100000
Convolution      layer43-conv     1 1 layer42-conv_layer42-act layer43-conv 0=512 1=3 2=1 3=1 4=1 5=0 6=1179648
BatchNorm        layer43-bn       1 1 layer43-conv layer43-conv_layer43-bn 0=512
Scale            layer43-scale    1 1 layer43-conv_layer43-bn layer43-conv_layer43-scale 0=512 1=1
ReLU             layer43-act      1 1 layer43-conv_layer43-scale layer43-conv_layer43-act 0=0.100000
Eltwise          layer44-shortcut 2 1 layer41-shortcut_splitncnn_0 layer43-conv_layer43-act layer44-shortcut 0=1 -23301=0
Split            splitncnn_14     1 2 layer44-shortcut layer44-shortcut_splitncnn_0 layer44-shortcut_splitncnn_1
Convolution      layer45-conv     1 1 layer44-shortcut_splitncnn_1 layer45-conv 0=256 1=1 2=1 3=1 4=0 5=0 6=131072
BatchNorm        layer45-bn       1 1 layer45-conv layer45-conv_layer45-bn 0=256
Scale            layer45-scale    1 1 layer45-conv_layer45-bn layer45-conv_layer45-scale 0=256 1=1
ReLU             layer45-act      1 1 layer45-conv_layer45-scale layer45-conv_layer45-act 0=0.100000
Convolution      layer46-conv     1 1 layer45-conv_layer45-act layer46-conv 0=512 1=3 2=1 3=1 4=1 5=0 6=1179648
BatchNorm        layer46-bn       1 1 layer46-conv layer46-conv_layer46-bn 0=512
Scale            layer46-scale    1 1 layer46-conv_layer46-bn layer46-conv_layer46-scale 0=512 1=1
ReLU             layer46-act      1 1 layer46-conv_layer46-scale layer46-conv_layer46-act 0=0.100000
Eltwise          layer47-shortcut 2 1 layer44-shortcut_splitncnn_0 layer46-conv_layer46-act layer47-shortcut 0=1 -23301=0
Split            splitncnn_15     1 2 layer47-shortcut layer47-shortcut_splitncnn_0 layer47-shortcut_splitncnn_1
Convolution      layer48-conv     1 1 layer47-shortcut_splitncnn_1 layer48-conv 0=256 1=1 2=1 3=1 4=0 5=0 6=131072
BatchNorm        layer48-bn       1 1 layer48-conv layer48-conv_layer48-bn 0=256
Scale            layer48-scale    1 1 layer48-conv_layer48-bn layer48-conv_layer48-scale 0=256 1=1
ReLU             layer48-act      1 1 layer48-conv_layer48-scale layer48-conv_layer48-act 0=0.100000
Convolution      layer49-conv     1 1 layer48-conv_layer48-act layer49-conv 0=512 1=3 2=1 3=1 4=1 5=0 6=1179648
BatchNorm        layer49-bn       1 1 layer49-conv layer49-conv_layer49-bn 0=512
Scale            layer49-scale    1 1 layer49-conv_layer49-bn layer49-conv_layer49-scale 0=512 1=1
ReLU             layer49-act      1 1 layer49-conv_layer49-scale layer49-conv_layer49-act 0=0.100000
Eltwise          layer50-shortcut 2 1 layer47-shortcut_splitncnn_0 layer49-conv_layer49-act layer50-shortcut 0=1 -23301=0
Split            splitncnn_16     1 2 layer50-shortcut layer50-shortcut_splitncnn_0 layer50-shortcut_splitncnn_1
Convolution      layer51-conv     1 1 layer50-shortcut_splitncnn_1 layer51-conv 0=256 1=1 2=1 3=1 4=0 5=0 6=131072
BatchNorm        layer51-bn       1 1 layer51-conv layer51-conv_layer51-bn 0=256
Scale            layer51-scale    1 1 layer51-conv_layer51-bn layer51-conv_layer51-scale 0=256 1=1
ReLU             layer51-act      1 1 layer51-conv_layer51-scale layer51-conv_layer51-act 0=0.100000
Convolution      layer52-conv     1 1 layer51-conv_layer51-act layer52-conv 0=512 1=3 2=1 3=1 4=1 5=0 6=1179648
BatchNorm        layer52-bn       1 1 layer52-conv layer52-conv_layer52-bn 0=512
Scale            layer52-scale    1 1 layer52-conv_layer52-bn layer52-conv_layer52-scale 0=512 1=1
ReLU             layer52-act      1 1 layer52-conv_layer52-scale layer52-conv_layer52-act 0=0.100000
Eltwise          layer53-shortcut 2 1 layer50-shortcut_splitncnn_0 layer52-conv_layer52-act layer53-shortcut 0=1 -23301=0
Split            splitncnn_17     1 2 layer53-shortcut layer53-shortcut_splitncnn_0 layer53-shortcut_splitncnn_1
Convolution      layer54-conv     1 1 layer53-shortcut_splitncnn_1 layer54-conv 0=256 1=1 2=1 3=1 4=0 5=0 6=131072
BatchNorm        layer54-bn       1 1 layer54-conv layer54-conv_layer54-bn 0=256
Scale            layer54-scale    1 1 layer54-conv_layer54-bn layer54-conv_layer54-scale 0=256 1=1
ReLU             layer54-act      1 1 layer54-conv_layer54-scale layer54-conv_layer54-act 0=0.100000
Convolution      layer55-conv     1 1 layer54-conv_layer54-act layer55-conv 0=512 1=3 2=1 3=1 4=1 5=0 6=1179648
BatchNorm        layer55-bn       1 1 layer55-conv layer55-conv_layer55-bn 0=512
Scale            layer55-scale    1 1 layer55-conv_layer55-bn layer55-conv_layer55-scale 0=512 1=1
ReLU             layer55-act      1 1 layer55-conv_layer55-scale layer55-conv_layer55-act 0=0.100000
Eltwise          layer56-shortcut 2 1 layer53-shortcut_splitncnn_0 layer55-conv_layer55-act layer56-shortcut 0=1 -23301=0
Split            splitncnn_18     1 2 layer56-shortcut layer56-shortcut_splitncnn_0 layer56-shortcut_splitncnn_1
Convolution      layer57-conv     1 1 layer56-shortcut_splitncnn_1 layer57-conv 0=256 1=1 2=1 3=1 4=0 5=0 6=131072
BatchNorm        layer57-bn       1 1 layer57-conv layer57-conv_layer57-bn 0=256
Scale            layer57-scale    1 1 layer57-conv_layer57-bn layer57-conv_layer57-scale 0=256 1=1
ReLU             layer57-act      1 1 layer57-conv_layer57-scale layer57-conv_layer57-act 0=0.100000
Convolution      layer58-conv     1 1 layer57-conv_layer57-act layer58-conv 0=512 1=3 2=1 3=1 4=1 5=0 6=1179648
BatchNorm        layer58-bn       1 1 layer58-conv layer58-conv_layer58-bn 0=512
Scale            layer58-scale    1 1 layer58-conv_layer58-bn layer58-conv_layer58-scale 0=512 1=1
ReLU             layer58-act      1 1 layer58-conv_layer58-scale layer58-conv_layer58-act 0=0.100000
Eltwise          layer59-shortcut 2 1 layer56-shortcut_splitncnn_0 layer58-conv_layer58-act layer59-shortcut 0=1 -23301=0
Split            splitncnn_19     1 2 layer59-shortcut layer59-shortcut_splitncnn_0 layer59-shortcut_splitncnn_1
Convolution      layer60-conv     1 1 layer59-shortcut_splitncnn_1 layer60-conv 0=256 1=1 2=1 3=1 4=0 5=0 6=131072
BatchNorm        layer60-bn       1 1 layer60-conv layer60-conv_layer60-bn 0=256
Scale            layer60-scale    1 1 layer60-conv_layer60-bn layer60-conv_layer60-scale 0=256 1=1
ReLU             layer60-act      1 1 layer60-conv_layer60-scale layer60-conv_layer60-act 0=0.100000
Convolution      layer61-conv     1 1 layer60-conv_layer60-act layer61-conv 0=512 1=3 2=1 3=1 4=1 5=0 6=1179648
BatchNorm        layer61-bn       1 1 layer61-conv layer61-conv_layer61-bn 0=512
Scale            layer61-scale    1 1 layer61-conv_layer61-bn layer61-conv_layer61-scale 0=512 1=1
ReLU             layer61-act      1 1 layer61-conv_layer61-scale layer61-conv_layer61-act 0=0.100000
Eltwise          layer62-shortcut 2 1 layer59-shortcut_splitncnn_0 layer61-conv_layer61-act layer62-shortcut 0=1 -23301=0
Split            splitncnn_20     1 2 layer62-shortcut layer62-shortcut_splitncnn_0 layer62-shortcut_splitncnn_1
Convolution      layer63-conv     1 1 layer62-shortcut_splitncnn_1 layer63-conv 0=1024 1=3 2=1 3=2 4=1 5=0 6=4718592
BatchNorm        layer63-bn       1 1 layer63-conv layer63-conv_layer63-bn 0=1024
Scale            layer63-scale    1 1 layer63-conv_layer63-bn layer63-conv_layer63-scale 0=1024 1=1
ReLU             layer63-act      1 1 layer63-conv_layer63-scale layer63-conv_layer63-act 0=0.100000
Split            splitncnn_21     1 2 layer63-conv_layer63-act layer63-conv_layer63-act_splitncnn_0 layer63-conv_layer63-act_splitncnn_1
Convolution      layer64-conv     1 1 layer63-conv_layer63-act_splitncnn_1 layer64-conv 0=512 1=1 2=1 3=1 4=0 5=0 6=524288
BatchNorm        layer64-bn       1 1 layer64-conv layer64-conv_layer64-bn 0=512
Scale            layer64-scale    1 1 layer64-conv_layer64-bn layer64-conv_layer64-scale 0=512 1=1
ReLU             layer64-act      1 1 layer64-conv_layer64-scale layer64-conv_layer64-act 0=0.100000
Convolution      layer65-conv     1 1 layer64-conv_layer64-act layer65-conv 0=1024 1=3 2=1 3=1 4=1 5=0 6=4718592
BatchNorm        layer65-bn       1 1 layer65-conv layer65-conv_layer65-bn 0=1024
Scale            layer65-scale    1 1 layer65-conv_layer65-bn layer65-conv_layer65-scale 0=1024 1=1
ReLU             layer65-act      1 1 layer65-conv_layer65-scale layer65-conv_layer65-act 0=0.100000
Eltwise          layer66-shortcut 2 1 layer63-conv_layer63-act_splitncnn_0 layer65-conv_layer65-act layer66-shortcut 0=1 -23301=0
Split            splitncnn_22     1 2 layer66-shortcut layer66-shortcut_splitncnn_0 layer66-shortcut_splitncnn_1
Convolution      layer67-conv     1 1 layer66-shortcut_splitncnn_1 layer67-conv 0=512 1=1 2=1 3=1 4=0 5=0 6=524288
BatchNorm        layer67-bn       1 1 layer67-conv layer67-conv_layer67-bn 0=512
Scale            layer67-scale    1 1 layer67-conv_layer67-bn layer67-conv_layer67-scale 0=512 1=1
ReLU             layer67-act      1 1 layer67-conv_layer67-scale layer67-conv_layer67-act 0=0.100000
Convolution      layer68-conv     1 1 layer67-conv_layer67-act layer68-conv 0=1024 1=3 2=1 3=1 4=1 5=0 6=4718592
BatchNorm        layer68-bn       1 1 layer68-conv layer68-conv_layer68-bn 0=1024
Scale            layer68-scale    1 1 layer68-conv_layer68-bn layer68-conv_layer68-scale 0=1024 1=1
ReLU             layer68-act      1 1 layer68-conv_layer68-scale layer68-conv_layer68-act 0=0.100000
Eltwise          layer69-shortcut 2 1 layer66-shortcut_splitncnn_0 layer68-conv_layer68-act layer69-shortcut 0=1 -23301=0
Split            splitncnn_23     1 2 layer69-shortcut layer69-shortcut_splitncnn_0 layer69-shortcut_splitncnn_1
Convolution      layer70-conv     1 1 layer69-shortcut_splitncnn_1 layer70-conv 0=512 1=1 2=1 3=1 4=0 5=0 6=524288
BatchNorm        layer70-bn       1 1 layer70-conv layer70-conv_layer70-bn 0=512
Scale            layer70-scale    1 1 layer70-conv_layer70-bn layer70-conv_layer70-scale 0=512 1=1
ReLU             layer70-act      1 1 layer70-conv_layer70-scale layer70-conv_layer70-act 0=0.100000
Convolution      layer71-conv     1 1 layer70-conv_layer70-act layer71-conv 0=1024 1=3 2=1 3=1 4=1 5=0 6=4718592
BatchNorm        layer71-bn       1 1 layer71-conv layer71-conv_layer71-bn 0=1024
Scale            layer71-scale    1 1 layer71-conv_layer71-bn layer71-conv_layer71-scale 0=1024 1=1
ReLU             layer71-act      1 1 layer71-conv_layer71-scale layer71-conv_layer71-act 0=0.100000
Eltwise          layer72-shortcut 2 1 layer69-shortcut_splitncnn_0 layer71-conv_layer71-act layer72-shortcut 0=1 -23301=0
Split            splitncnn_24     1 2 layer72-shortcut layer72-shortcut_splitncnn_0 layer72-shortcut_splitncnn_1
Convolution      layer73-conv     1 1 layer72-shortcut_splitncnn_1 layer73-conv 0=512 1=1 2=1 3=1 4=0 5=0 6=524288
BatchNorm        layer73-bn       1 1 layer73-conv layer73-conv_layer73-bn 0=512
Scale            layer73-scale    1 1 layer73-conv_layer73-bn layer73-conv_layer73-scale 0=512 1=1
ReLU             layer73-act      1 1 layer73-conv_layer73-scale layer73-conv_layer73-act 0=0.100000
Convolution      layer74-conv     1 1 layer73-conv_layer73-act layer74-conv 0=1024 1=3 2=1 3=1 4=1 5=0 6=4718592
BatchNorm        layer74-bn       1 1 layer74-conv layer74-conv_layer74-bn 0=1024
Scale            layer74-scale    1 1 layer74-conv_layer74-bn layer74-conv_layer74-scale 0=1024 1=1
ReLU             layer74-act      1 1 layer74-conv_layer74-scale layer74-conv_layer74-act 0=0.100000
Eltwise          layer75-shortcut 2 1 layer72-shortcut_splitncnn_0 layer74-conv_layer74-act layer75-shortcut 0=1 -23301=0
Convolution      layer76-conv     1 1 layer75-shortcut layer76-conv 0=512 1=1 2=1 3=1 4=0 5=0 6=524288
BatchNorm        layer76-bn       1 1 layer76-conv layer76-conv_layer76-bn 0=512
Scale            layer76-scale    1 1 layer76-conv_layer76-bn layer76-conv_layer76-scale 0=512 1=1
ReLU             layer76-act      1 1 layer76-conv_layer76-scale layer76-conv_layer76-act 0=0.100000
Convolution      layer77-conv     1 1 layer76-conv_layer76-act layer77-conv 0=1024 1=3 2=1 3=1 4=1 5=0 6=4718592
BatchNorm        layer77-bn       1 1 layer77-conv layer77-conv_layer77-bn 0=1024
Scale            layer77-scale    1 1 layer77-conv_layer77-bn layer77-conv_layer77-scale 0=1024 1=1
ReLU             layer77-act      1 1 layer77-conv_layer77-scale layer77-conv_layer77-act 0=0.100000
Convolution      layer78-conv     1 1 layer77-conv_layer77-act layer78-conv 0=512 1=1 2=1 3=1 4=0 5=0 6=524288
BatchNorm        layer78-bn       1 1 layer78-conv layer78-conv_layer78-bn 0=512
Scale            layer78-scale    1 1 layer78-conv_layer78-bn layer78-conv_layer78-scale 0=512 1=1
ReLU             layer78-act      1 1 layer78-conv_layer78-scale layer78-conv_layer78-act 0=0.100000
Convolution      layer79-conv     1 1 layer78-conv_layer78-act layer79-conv 0=1024 1=3 2=1 3=1 4=1 5=0 6=4718592
BatchNorm        layer79-bn       1 1 layer79-conv layer79-conv_layer79-bn 0=1024
Scale            layer79-scale    1 1 layer79-conv_layer79-bn layer79-conv_layer79-scale 0=1024 1=1
ReLU             layer79-act      1 1 layer79-conv_layer79-scale layer79-conv_layer79-act 0=0.100000
Convolution      layer80-conv     1 1 layer79-conv_layer79-act layer80-conv 0=512 1=1 2=1 3=1 4=0 5=0 6=524288
BatchNorm        layer80-bn       1 1 layer80-conv layer80-conv_layer80-bn 0=512
Scale            layer80-scale    1 1 layer80-conv_layer80-bn layer80-conv_layer80-scale 0=512 1=1
ReLU             layer80-act      1 1 layer80-conv_layer80-scale layer80-conv_layer80-act 0=0.100000
Split            splitncnn_25     1 2 layer80-conv_layer80-act layer80-conv_layer80-act_splitncnn_0 layer80-conv_layer80-act_splitncnn_1
Convolution      layer81-conv     1 1 layer80-conv_layer80-act_splitncnn_1 layer81-conv 0=1024 1=3 2=1 3=1 4=1 5=0 6=4718592
BatchNorm        layer81-bn       1 1 layer81-conv layer81-conv_layer81-bn 0=1024
Scale            layer81-scale    1 1 layer81-conv_layer81-bn layer81-conv_layer81-scale 0=1024 1=1
ReLU             layer81-act      1 1 layer81-conv_layer81-scale layer81-conv_layer81-act 0=0.100000
Convolution      layer82-conv     1 1 layer81-conv_layer81-act layer82-conv 0=255 1=1 2=1 3=1 4=0 5=1 6=261120
Concat           layer83-yolo     1 1 layer82-conv layer83-yolo 0=0
Concat           layer84-route    1 1 layer80-conv_layer80-act_splitncnn_0 layer84-route 0=0
Convolution      layer85-conv     1 1 layer84-route layer85-conv 0=256 1=1 2=1 3=1 4=0 5=0 6=131072
BatchNorm        layer85-bn       1 1 layer85-conv layer85-conv_layer85-bn 0=256
Scale            layer85-scale    1 1 layer85-conv_layer85-bn layer85-conv_layer85-scale 0=256 1=1
ReLU             layer85-act      1 1 layer85-conv_layer85-scale layer85-conv_layer85-act 0=0.100000
DeconvolutionDepthWise layer86-upsample 1 1 layer85-conv_layer85-act layer86-upsample 0=256 1=4 2=1 3=2 4=1 5=0 6=4096 7=256
Concat           layer87-route    2 1 layer86-upsample layer62-shortcut_splitncnn_0 layer87-route 0=0
Convolution      layer88-conv     1 1 layer87-route layer88-conv 0=256 1=1 2=1 3=1 4=0 5=0 6=196608
BatchNorm        layer88-bn       1 1 layer88-conv layer88-conv_layer88-bn 0=256
Scale            layer88-scale    1 1 layer88-conv_layer88-bn layer88-conv_layer88-scale 0=256 1=1
ReLU             layer88-act      1 1 layer88-conv_layer88-scale layer88-conv_layer88-act 0=0.100000
Convolution      layer89-conv     1 1 layer88-conv_layer88-act layer89-conv 0=512 1=3 2=1 3=1 4=1 5=0 6=1179648
BatchNorm        layer89-bn       1 1 layer89-conv layer89-conv_layer89-bn 0=512
Scale            layer89-scale    1 1 layer89-conv_layer89-bn layer89-conv_layer89-scale 0=512 1=1
ReLU             layer89-act      1 1 layer89-conv_layer89-scale layer89-conv_layer89-act 0=0.100000
Convolution      layer90-conv     1 1 layer89-conv_layer89-act layer90-conv 0=256 1=1 2=1 3=1 4=0 5=0 6=131072
BatchNorm        layer90-bn       1 1 layer90-conv layer90-conv_layer90-bn 0=256
Scale            layer90-scale    1 1 layer90-conv_layer90-bn layer90-conv_layer90-scale 0=256 1=1
ReLU             layer90-act      1 1 layer90-conv_layer90-scale layer90-conv_layer90-act 0=0.100000
Convolution      layer91-conv     1 1 layer90-conv_layer90-act layer91-conv 0=512 1=3 2=1 3=1 4=1 5=0 6=1179648
BatchNorm        layer91-bn       1 1 layer91-conv layer91-conv_layer91-bn 0=512
Scale            layer91-scale    1 1 layer91-conv_layer91-bn layer91-conv_layer91-scale 0=512 1=1
ReLU             layer91-act      1 1 layer91-conv_layer91-scale layer91-conv_layer91-act 0=0.100000
Convolution      layer92-conv     1 1 layer91-conv_layer91-act layer92-conv 0=256 1=1 2=1 3=1 4=0 5=0 6=131072
BatchNorm        layer92-bn       1 1 layer92-conv layer92-conv_layer92-bn 0=256
Scale            layer92-scale    1 1 layer92-conv_layer92-bn layer92-conv_layer92-scale 0=256 1=1
ReLU             layer92-act      1 1 layer92-conv_layer92-scale layer92-conv_layer92-act 0=0.100000
Split            splitncnn_26     1 2 layer92-conv_layer92-act layer92-conv_layer92-act_splitncnn_0 layer92-conv_layer92-act_splitncnn_1
Convolution      layer93-conv     1 1 layer92-conv_layer92-act_splitncnn_1 layer93-conv 0=512 1=3 2=1 3=1 4=1 5=0 6=1179648
BatchNorm        layer93-bn       1 1 layer93-conv layer93-conv_layer93-bn 0=512
Scale            layer93-scale    1 1 layer93-conv_layer93-bn layer93-conv_layer93-scale 0=512 1=1
ReLU             layer93-act      1 1 layer93-conv_layer93-scale layer93-conv_layer93-act 0=0.100000
Convolution      layer94-conv     1 1 layer93-conv_layer93-act layer94-conv 0=255 1=1 2=1 3=1 4=0 5=1 6=130560
Concat           layer95-yolo     1 1 layer94-conv layer95-yolo 0=0
Concat           layer96-route    1 1 layer92-conv_layer92-act_splitncnn_0 layer96-route 0=0
Convolution      layer97-conv     1 1 layer96-route layer97-conv 0=128 1=1 2=1 3=1 4=0 5=0 6=32768
BatchNorm        layer97-bn       1 1 layer97-conv layer97-conv_layer97-bn 0=128
Scale            layer97-scale    1 1 layer97-conv_layer97-bn layer97-conv_layer97-scale 0=128 1=1
ReLU             layer97-act      1 1 layer97-conv_layer97-scale layer97-conv_layer97-act 0=0.100000
DeconvolutionDepthWise layer98-upsample 1 1 layer97-conv_layer97-act layer98-upsample 0=128 1=4 2=1 3=2 4=1 5=0 6=2048 7=128
Concat           layer99-route    2 1 layer98-upsample layer37-shortcut_splitncnn_0 layer99-route 0=0
Convolution      layer100-conv    1 1 layer99-route layer100-conv 0=128 1=1 2=1 3=1 4=0 5=0 6=49152
BatchNorm        layer100-bn      1 1 layer100-conv layer100-conv_layer100-bn 0=128
Scale            layer100-scale   1 1 layer100-conv_layer100-bn layer100-conv_layer100-scale 0=128 1=1
ReLU             layer100-act     1 1 layer100-conv_layer100-scale layer100-conv_layer100-act 0=0.100000
Convolution      layer101-conv    1 1 layer100-conv_layer100-act layer101-conv 0=256 1=3 2=1 3=1 4=1 5=0 6=294912
BatchNorm        layer101-bn      1 1 layer101-conv layer101-conv_layer101-bn 0=256
Scale            layer101-scale   1 1 layer101-conv_layer101-bn layer101-conv_layer101-scale 0=256 1=1
ReLU             layer101-act     1 1 layer101-conv_layer101-scale layer101-conv_layer101-act 0=0.100000
Convolution      layer102-conv    1 1 layer101-conv_layer101-act layer102-conv 0=128 1=1 2=1 3=1 4=0 5=0 6=32768
BatchNorm        layer102-bn      1 1 layer102-conv layer102-conv_layer102-bn 0=128
Scale            layer102-scale   1 1 layer102-conv_layer102-bn layer102-conv_layer102-scale 0=128 1=1
ReLU             layer102-act     1 1 layer102-conv_layer102-scale layer102-conv_layer102-act 0=0.100000
Convolution      layer103-conv    1 1 layer102-conv_layer102-act layer103-conv 0=256 1=3 2=1 3=1 4=1 5=0 6=294912
BatchNorm        layer103-bn      1 1 layer103-conv layer103-conv_layer103-bn 0=256
Scale            layer103-scale   1 1 layer103-conv_layer103-bn layer103-conv_layer103-scale 0=256 1=1
ReLU             layer103-act     1 1 layer103-conv_layer103-scale layer103-conv_layer103-act 0=0.100000
Convolution      layer104-conv    1 1 layer103-conv_layer103-act layer104-conv 0=128 1=1 2=1 3=1 4=0 5=0 6=32768
BatchNorm        layer104-bn      1 1 layer104-conv layer104-conv_layer104-bn 0=128
Scale            layer104-scale   1 1 layer104-conv_layer104-bn layer104-conv_layer104-scale 0=128 1=1
ReLU             layer104-act     1 1 layer104-conv_layer104-scale layer104-conv_layer104-act 0=0.100000
Convolution      layer105-conv    1 1 layer104-conv_layer104-act layer105-conv 0=256 1=3 2=1 3=1 4=1 5=0 6=294912
BatchNorm        layer105-bn      1 1 layer105-conv layer105-conv_layer105-bn 0=256
Scale            layer105-scale   1 1 layer105-conv_layer105-bn layer105-conv_layer105-scale 0=256 1=1
ReLU             layer105-act     1 1 layer105-conv_layer105-scale layer105-conv_layer105-act 0=0.100000
Convolution      layer106-conv    1 1 layer105-conv_layer105-act layer106-conv 0=255 1=1 2=1 3=1 4=0 5=1 6=65280
Yolov3DetectionOutput detection_out    3 1 layer83-yolo layer95-yolo layer106-conv detection_out 0=80 1=3 2=0.010000 3=0.450000 -23304=18,10.000000,13.000000,16.000000,30.000000,33.000000,23.000000,30.000000,61.000000,62.000000,45.000000,59.000000,119.000000,116.000000,90.000000,156.000000,198.000000,373.000000,326.000000 -23305=9,6.000000,7.000000,8.000000,3.000000,4.000000,5.000000,0.000000,1.000000,2.000000 -23306=3,32.000000,16.000000,8.000000 7=3
